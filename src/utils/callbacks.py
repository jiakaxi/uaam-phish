"""
PyTorch Lightning è‡ªå®šä¹‰å›è°ƒ
ç”¨äºå®éªŒç»“æœçš„è‡ªåŠ¨ä¿å­˜
"""

import numpy as np
from pathlib import Path
from pytorch_lightning.callbacks import Callback
import torch


class ExperimentResultsCallback(Callback):
    """
    å®éªŒç»“æœè‡ªåŠ¨ä¿å­˜å›è°ƒ
    åœ¨è®­ç»ƒç»“æŸåè‡ªåŠ¨ä¿å­˜æŒ‡æ ‡ã€å›¾è¡¨å’Œæ—¥å¿—
    """

    def __init__(self, experiment_tracker):
        """
        Args:
            experiment_tracker: ExperimentTracker å®ä¾‹
        """
        super().__init__()
        self.tracker = experiment_tracker
        self.test_outputs = []

    def on_train_start(self, trainer, pl_module):
        """è®­ç»ƒå¼€å§‹æ—¶è®°å½•"""
        self.tracker.log_text("=" * 60)
        self.tracker.log_text("è®­ç»ƒå¼€å§‹")
        self.tracker.log_text(f"æ¨¡å‹: {self.tracker.cfg.model.pretrained_name}")
        self.tracker.log_text(f"æ€»è½®æ•°: {self.tracker.cfg.train.epochs}")
        self.tracker.log_text("=" * 60)

    def on_train_epoch_end(self, trainer, pl_module):
        """æ¯ä¸ªè®­ç»ƒ epoch ç»“æŸæ—¶è®°å½•"""
        epoch = trainer.current_epoch

        # è·å–å½“å‰ epoch çš„æŒ‡æ ‡
        metrics = trainer.callback_metrics
        log_msg = f"Epoch {epoch}: "

        for key, value in metrics.items():
            if isinstance(value, torch.Tensor):
                log_msg += f"{key}={value.item():.4f} "

        self.tracker.log_text(log_msg)

    def on_train_end(self, trainer, pl_module):
        """è®­ç»ƒç»“æŸæ—¶ä¿å­˜ç»“æœ"""
        self.tracker.log_text("=" * 60)
        self.tracker.log_text("è®­ç»ƒå®Œæˆ")
        self.tracker.log_text("=" * 60)

        # å¤åˆ¶æ£€æŸ¥ç‚¹
        if trainer.log_dir:
            lightning_log_dir = Path(trainer.log_dir)
            self.tracker.copy_checkpoints(lightning_log_dir)

            # ä¿å­˜è®­ç»ƒå†å²æ›²çº¿
            metrics_csv = lightning_log_dir / "metrics.csv"
            if metrics_csv.exists():
                # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
                try:
                    from src.utils.visualizer import ResultVisualizer

                    ResultVisualizer.plot_training_curves(
                        metrics_csv,
                        save_path=self.tracker.results_dir / "training_curves.png",
                    )
                except ImportError:
                    print("âš ï¸  matplotlib æœªå®‰è£…,è·³è¿‡è®­ç»ƒæ›²çº¿ç»˜åˆ¶")
                except Exception as e:
                    print(f"âš ï¸  è®­ç»ƒæ›²çº¿ç»˜åˆ¶å¤±è´¥: {e}")

    def on_test_batch_end(
        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0
    ):
        """æ”¶é›†æµ‹è¯•æ‰¹æ¬¡çš„è¾“å‡º"""
        # è¿™ä¸ªæ–¹æ³•åœ¨æ¯ä¸ªæµ‹è¯•æ‰¹æ¬¡ç»“æŸæ—¶è°ƒç”¨
        # æˆ‘ä»¬éœ€è¦åœ¨ test_step ä¸­è¿”å›éœ€è¦çš„æ•°æ®
        pass

    def on_test_end(self, trainer, pl_module):
        """æµ‹è¯•ç»“æŸæ—¶ä¿å­˜æœ€ç»ˆç»“æœ"""
        self.tracker.log_text("=" * 60)
        self.tracker.log_text("æµ‹è¯•å®Œæˆ")
        self.tracker.log_text("=" * 60)

        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
        final_metrics = {}
        for key, value in trainer.callback_metrics.items():
            if isinstance(value, torch.Tensor):
                final_metrics[key] = value.item()
            else:
                final_metrics[key] = value

        self.tracker.save_metrics(final_metrics, stage="final")

        # ç”Ÿæˆå®éªŒæ€»ç»“
        summary = {
            "final_test_loss": final_metrics.get("test/loss", "N/A"),
            "final_test_f1": final_metrics.get("test/f1", "N/A"),
            "final_test_auroc": final_metrics.get("test/auroc", "N/A"),
            "final_test_fpr": final_metrics.get("test/fpr", "N/A"),
            "total_epochs": trainer.current_epoch + 1,
        }

        self.tracker.save_summary(summary)

        print("\n" + "=" * 60)
        print(f"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {self.tracker.exp_dir}")
        print("=" * 60)
        print(f"ğŸ“Š é…ç½®æ–‡ä»¶: {self.tracker.exp_dir / 'config.yaml'}")
        print(f"ğŸ“ˆ æŒ‡æ ‡æ–‡ä»¶: {self.tracker.results_dir / 'metrics_final.json'}")
        print(f"ğŸ“ æ£€æŸ¥ç‚¹: {self.tracker.checkpoints_dir}")
        print(f"ğŸ“ æ—¥å¿—: {self.tracker.logs_dir}")
        print("=" * 60)


class TestPredictionCollector(Callback):
    """
    æ”¶é›†æµ‹è¯•é›†çš„é¢„æµ‹ç»“æœï¼Œç”¨äºç»˜åˆ¶ ROC æ›²çº¿å’Œæ··æ·†çŸ©é˜µ
    """

    def __init__(self):
        super().__init__()
        self.y_true = []
        self.y_prob = []

    def on_test_batch_end(
        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0
    ):
        """æ”¶é›†æ¯ä¸ªæ‰¹æ¬¡çš„é¢„æµ‹"""
        # éœ€è¦åœ¨ LightningModule çš„ test_step ä¸­è¿”å› predictions
        if outputs is not None and "y_true" in outputs and "y_prob" in outputs:
            self.y_true.append(outputs["y_true"].cpu().numpy())
            self.y_prob.append(outputs["y_prob"].cpu().numpy())

    def on_test_end(self, trainer, pl_module):
        """æµ‹è¯•ç»“æŸååˆå¹¶æ‰€æœ‰é¢„æµ‹"""
        if self.y_true and self.y_prob:
            self.y_true = np.concatenate(self.y_true)
            self.y_prob = np.concatenate(self.y_prob)

    def get_predictions(self):
        """è·å–æ”¶é›†çš„é¢„æµ‹ç»“æœ"""
        return self.y_true, self.y_prob
