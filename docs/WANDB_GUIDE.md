# WandB äº‘ç«¯å®éªŒè·Ÿè¸ªæŒ‡å—

## ğŸ“Š ä»€ä¹ˆæ˜¯ WandBï¼Ÿ

**Weights & Biases (WandB)** æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æœºå™¨å­¦ä¹ å®éªŒè·Ÿè¸ªå¹³å°ï¼Œæä¾›ï¼š
- âœ… å®æ—¶æŒ‡æ ‡å¯è§†åŒ–
- âœ… è¶…å‚æ•°å¯¹æ¯”
- âœ… æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- âœ… å›¢é˜Ÿåä½œ
- âœ… æŠ¥å‘Šç”Ÿæˆ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£… WandB

```bash
pip install wandb
```

### 2. ç™»å½• WandB

```bash
# é¦–æ¬¡ä½¿ç”¨éœ€è¦ç™»å½•
wandb login

# æˆ–è€…è®¾ç½® API key
export WANDB_API_KEY=64e15c91404e5023801580b0d943af3ebef4a033
```

### 3. ä½¿ç”¨ WandB Logger

```bash
# ä½¿ç”¨ WandB logger
python scripts/train_hydra.py logger=wandb

# æŒ‡å®šé¡¹ç›®åç§°
export WANDB_PROJECT=my-phish-detection
python scripts/train_hydra.py logger=wandb

# ç¦»çº¿æ¨¡å¼ï¼ˆç¨ååŒæ­¥ï¼‰
python scripts/train_hydra.py logger=wandb logger.offline=true
```

---

## ğŸ¯ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶æˆ–å‘½ä»¤è¡Œä¸­è®¾ç½®ï¼š

```bash
# WandB é¡¹ç›®åç§°
export WANDB_PROJECT=uaam-phish

# WandB team/username
export WANDB_ENTITY=your-team-name

# å®éªŒæ ‡ç­¾
export WANDB_TAGS=url-only,baseline

# API Key
export WANDB_API_KEY=64e15c91404e5023801580b0d943af3ebef4a033

# ç¦»çº¿æ¨¡å¼
export WANDB_MODE=offline
```

### Hydra é…ç½®æ–‡ä»¶

ç¼–è¾‘ `configs/logger/wandb.yaml`:

```yaml
logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  project: uaam-phish
  name: ${run.name}
  offline: false
  log_model: true  # ä¸Šä¼ æ¨¡å‹æ£€æŸ¥ç‚¹
  tags: [url-only, roberta]
  notes: "URL-only baseline experiment"
```

### å‘½ä»¤è¡Œè¦†ç›–

```bash
# æ›´æ”¹é¡¹ç›®åç§°
python scripts/train_hydra.py logger=wandb logger.project=my-project

# å¯ç”¨æ¨¡å‹ä¸Šä¼ 
python scripts/train_hydra.py logger=wandb logger.log_model=true

# æ·»åŠ æ ‡ç­¾
python scripts/train_hydra.py logger=wandb logger.tags=[bert,baseline]
```

---

## ğŸ“ˆ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬è®­ç»ƒ

```bash
# æœ¬åœ°å¼€å‘ï¼ˆä½¿ç”¨ CSV loggerï¼‰
python scripts/train_hydra.py trainer=local

# æœåŠ¡å™¨è®­ç»ƒï¼ˆä½¿ç”¨ WandBï¼‰
python scripts/train_hydra.py trainer=server logger=wandb
```

### å®éªŒå¯¹æ¯”

```bash
# è¿è¡Œå¤šä¸ªå®éªŒ
python scripts/train_hydra.py logger=wandb run.name=exp1 model.dropout=0.1
python scripts/train_hydra.py logger=wandb run.name=exp2 model.dropout=0.2
python scripts/train_hydra.py logger=wandb run.name=exp3 model.dropout=0.3

# åœ¨ WandB Dashboard ä¸­å¯¹æ¯”ç»“æœ
```

### è¶…å‚æ•°æœç´¢

```bash
# ä½¿ç”¨ Hydra multirun
python scripts/train_hydra.py -m logger=wandb \\
  train.lr=1e-5,2e-5,5e-5 \\
  model.dropout=0.1,0.2,0.3 \\
  train.bs=16,32

# WandB ä¼šè‡ªåŠ¨è·Ÿè¸ªæ‰€æœ‰è¿è¡Œ
```

---

## ğŸ¨ WandB Dashboard åŠŸèƒ½

### 1. å®æ—¶æŒ‡æ ‡ç›‘æ§

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå®æ—¶æŸ¥çœ‹ï¼š
- Loss curves
- F1, AUROC, FPR
- Learning rate
- Gradient norms
- Consistency (S2): `val/consistency/acs`, `val/consistency/mr@Ï„_s`, `test/consistency/acs`

### 2. è¶…å‚æ•°å¯¹æ¯”

è‡ªåŠ¨è®°å½•å’Œå¯¹æ¯”ï¼š
- æ¨¡å‹é…ç½®
- è®­ç»ƒå‚æ•°
- æ•°æ®é…ç½®
- ç¡¬ä»¶è®¾ç½®

### 3. ç³»ç»Ÿç›‘æ§

è·Ÿè¸ªï¼š
- GPU/CPU ä½¿ç”¨ç‡
- å†…å­˜ä½¿ç”¨
- ç½‘ç»œæµé‡
- è®­ç»ƒæ—¶é—´

### 4. ç”ŸæˆæŠ¥å‘Š

åˆ›å»ºäº¤äº’å¼æŠ¥å‘Šï¼š
- å®éªŒæ€»ç»“
- å¯è§†åŒ–å›¾è¡¨
- å›¢é˜Ÿåˆ†äº«

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰æ—¥å¿—

åœ¨ä»£ç ä¸­æ·»åŠ è‡ªå®šä¹‰æ—¥å¿—ï¼š

```python
# åœ¨ LightningModule ä¸­
import wandb

def training_step(self, batch, batch_idx):
    loss = ...

    # è®°å½•è‡ªå®šä¹‰æŒ‡æ ‡
    self.log("custom/metric", value)

    # è®°å½•å›¾åƒ
    if self.logger and isinstance(self.logger, WandbLogger):
        self.logger.experiment.log({
            "predictions": wandb.Image(img)
        })

    return loss
```

### 2. ä¿å­˜ Artifacts

ä¿å­˜é‡è¦æ–‡ä»¶ï¼š

```python
# ä¿å­˜æ¨¡å‹
wandb.save("model.ckpt")

# ä¿å­˜æ•°æ®é›†
artifact = wandb.Artifact("dataset", type="dataset")
artifact.add_file("data/train.csv")
wandb.log_artifact(artifact)
```

### 3. å›¢é˜Ÿåä½œ

```bash
# è®¾ç½® team
export WANDB_ENTITY=your-team

# æ‰€æœ‰æˆå‘˜å¯ä»¥æŸ¥çœ‹å®éªŒ
python scripts/train_hydra.py logger=wandb
```

---

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. å‘½åè§„èŒƒ

```bash
# ä½¿ç”¨æè¿°æ€§çš„å®éªŒåç§°
python scripts/train_hydra.py logger=wandb \\
  run.name="roberta-base_lr2e5_bs32_dropout02"
```

### 2. ä½¿ç”¨æ ‡ç­¾

```bash
# æ·»åŠ æœ‰æ„ä¹‰çš„æ ‡ç­¾
python scripts/train_hydra.py logger=wandb \\
  logger.tags=[url-only,baseline,roberta,v1]
```

### 3. æ·»åŠ å¤‡æ³¨

ç¼–è¾‘ `configs/logger/wandb.yaml`:

```yaml
logger:
  notes: |
    å®éªŒç›®æ ‡ï¼š
    - æµ‹è¯• RoBERTa-base ä½œä¸º URL ç¼–ç å™¨
    - åŸºçº¿æ€§èƒ½è¯„ä¼°
    å˜æ›´ï¼š
    - å¢åŠ  dropout åˆ° 0.2
    - ä½¿ç”¨ cosine scheduler
```

### 4. ç»„ç»‡é¡¹ç›®

```bash
# æŒ‰åŠŸèƒ½ç»„ç»‡é¡¹ç›®
WANDB_PROJECT=uaam-phish-url python scripts/train_hydra.py logger=wandb
WANDB_PROJECT=uaam-phish-multimodal python scripts/train_hydra.py logger=wandb
```

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: WandB ç™»å½•å¤±è´¥

```bash
# é‡æ–°ç™»å½•
wandb login --relogin

# æˆ–è®¾ç½® API key
export WANDB_API_KEY=64e15c91404e5023801580b0d943af3ebef4a033
```

### é—®é¢˜ 2: ç½‘ç»œé—®é¢˜

```bash
# ä½¿ç”¨ç¦»çº¿æ¨¡å¼
python scripts/train_hydra.py logger=wandb logger.offline=true

# ç¨ååŒæ­¥
wandb sync outputs/2025-10-22/18-45-00/wandb/latest-run
```

### é—®é¢˜ 3: æ—¥å¿—è¿‡å¤š

```bash
# å‡å°‘æ—¥å¿—é¢‘ç‡
python scripts/train_hydra.py logger=wandb train.log_every=100
```

---

## ğŸ“š å…¶ä»– Logger é€‰é¡¹

### TensorBoard

```bash
python scripts/train_hydra.py logger=tensorboard

# æŸ¥çœ‹
tensorboard --logdir outputs/
```

### CSV Loggerï¼ˆé»˜è®¤ï¼‰

```bash
python scripts/train_hydra.py logger=csv

# ç»“æœåœ¨ outputs/*/metrics.csv
```

### MLflow

```bash
# éœ€è¦å…ˆå®‰è£…
pip install mlflow

# åˆ›å»º configs/logger/mlflow.yaml
# ç„¶åä½¿ç”¨
python scripts/train_hydra.py logger=mlflow
```

---

## ğŸ”— èµ„æº

- [WandB å®˜æ–¹æ–‡æ¡£](https://docs.wandb.ai/)
- [PyTorch Lightning + WandB](https://docs.wandb.ai/guides/integrations/lightning)
- [Hydra + WandB](https://hydra.cc/docs/plugins/wandb_sweeper/)

---

**ç»´æŠ¤è€…:** UAAM-Phish Team
**æœ€åæ›´æ–°:** 2025-10-22
