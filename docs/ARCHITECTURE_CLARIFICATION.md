# æ¶æ„æ¾„æ¸…è¯´æ˜

> **æ›´æ–°æ—¥æœŸ:** 2025-10-22
> **é‡è¦æ€§:** âš ï¸ å¿…è¯»

---

## âš ï¸ é‡è¦æ¾„æ¸…

### å½“å‰å®é™…æ¶æ„

**ä½ çš„ä»£ç åº“ä½¿ç”¨ï¼šå­—ç¬¦çº§ BiLSTM + Lightning + OmegaConfï¼ˆä¸»æµæ–¹æ¡ˆï¼‰**

âŒ **ä¸æ˜¯** HuggingFace BERT/RoBERTa ä¸ºä¸»
âœ… **æ˜¯** å­—ç¬¦çº§ BiLSTM ä¸ºä¸»

---

## ğŸ“Š åŒç¼–ç å™¨æ¶æ„

### 1. ä¸»æµæ–¹æ¡ˆï¼šå­—ç¬¦çº§ BiLSTM âœ…

**æ–‡ä»¶ï¼š** `src/models/url_encoder.py` (ç¬¬ 10-54 è¡Œ)

```python
class URLEncoder(nn.Module):
    """Character-level BiLSTM encoder producing vectors in R^256 by default."""

    # æ¶æ„
    å­—ç¬¦åµŒå…¥ (vocab_size=128, embedding_dim=128)
        â†“
    BiLSTM (hidden_dim=128, num_layers=2, bidirectional=True)
        â†“
    æŠ•å½±å±‚ (proj_dim=256)
        â†“
    è¾“å‡º: [B, 256] åµŒå…¥å‘é‡
```

**ç‰¹ç‚¹ï¼š**
- âœ… å­—ç¬¦çº§ç¼–ç ï¼ˆord(ch)ï¼‰
- âœ… ä¸éœ€è¦ HuggingFace
- âœ… è½»é‡çº§ã€å¿«é€Ÿ
- âœ… é€‚åˆ URL ç‰¹å¾

**ä½¿ç”¨ä½ç½®ï¼š**
- `src/systems/url_only_module.py` - é»˜è®¤ä½¿ç”¨
- `src/datamodules/url_datamodule.py` - é…å¥—æ•°æ®æ¨¡å—
- `src/data/url_dataset.py` - å­—ç¬¦çº§ç¼–ç 

---

### 2. Legacy æ–¹æ¡ˆï¼šHuggingFace BERT âš ï¸

**æ–‡ä»¶ï¼š** `src/models/url_encoder.py` (ç¬¬ 57-84 è¡Œ)

```python
class UrlBertEncoder(nn.Module):
    """
    Legacy HuggingFace-based encoder kept for backward compatibility with
    multimodal experiments.
    """
    # å·²æ˜ç¡®æ ‡è®°ä¸º Legacyï¼
```

**ç‰¹ç‚¹ï¼š**
- âš ï¸ ä»…ç”¨äºå‘åå…¼å®¹
- âš ï¸ å¤šæ¨¡æ€å®éªŒå¯èƒ½éœ€è¦
- âš ï¸ éœ€è¦ HuggingFace ä¾èµ–
- âš ï¸ è¾ƒé‡ã€è¾ƒæ…¢

**ä¿ç•™åŸå› ï¼š**
- å¤šæ¨¡æ€èåˆå®éªŒå¯èƒ½éœ€è¦ç»Ÿä¸€çš„ 768-dim åµŒå…¥
- HTML å’Œå›¾åƒç¼–ç å™¨å¯èƒ½åŸºäº BERT/ViT
- æ–¹ä¾¿æ€§èƒ½å¯¹æ¯”å®éªŒ

---

## ğŸ”§ é…ç½®æ–‡ä»¶å¯¹åº”

### ä¸»æµé…ç½®ï¼ˆå­—ç¬¦çº§ BiLSTMï¼‰

```yaml
# configs/model/url_encoder.yaml
model:
  _target_: src.models.url_encoder.URLEncoder  # âœ… å­—ç¬¦çº§
  vocab_size: 128
  embedding_dim: 128
  hidden_dim: 128
  num_layers: 2
  bidirectional: true
  dropout: 0.1
  pad_id: 0
  proj_dim: 256
  max_len: 256
  num_classes: 2

# configs/data/url_only.yaml
data:
  train_csv: data/processed/train.csv
  val_csv: data/processed/val.csv
  test_csv: data/processed/test.csv

# configs/trainer/default.yaml
train:
  lr: 1.0e-3        # âœ… BiLSTM å­¦ä¹ ç‡ï¼ˆè¾ƒå¤§ï¼‰
  bs: 32
  epochs: 10
```

### Legacy é…ç½®ï¼ˆHuggingFace BERTï¼‰

```yaml
# configs/model/url_encoder_legacy.yaml
model:
  _target_: src.models.url_encoder.UrlBertEncoder  # âš ï¸ Legacy
  pretrained_name: roberta-base
  dropout: 0.2

# éœ€è¦ä¸åŒçš„è®­ç»ƒå‚æ•°
train:
  lr: 2.0e-5        # âš ï¸ BERT å­¦ä¹ ç‡ï¼ˆè¾ƒå°ï¼‰
  bs: 16            # âš ï¸ BERT æ‰¹æ¬¡ï¼ˆè¾ƒå°ï¼‰
```

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### é»˜è®¤ä½¿ç”¨ï¼ˆå­—ç¬¦çº§ BiLSTMï¼‰

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆå­—ç¬¦çº§ï¼‰
python scripts/train_hydra.py

# æˆ–æ˜ç¡®æŒ‡å®š
python scripts/train_hydra.py model=url_encoder
```

### ä½¿ç”¨ Legacy æ–¹æ¡ˆï¼ˆHuggingFaceï¼‰

```bash
# ä½¿ç”¨ Legacy é…ç½®
python scripts/train_hydra.py model=url_encoder_legacy

# éœ€è¦è°ƒæ•´å­¦ä¹ ç‡
python scripts/train_hydra.py \\
  model=url_encoder_legacy \\
  train.lr=2e-5 \\
  train.bs=16
```

---

## ğŸ“‚ å®Œæ•´æ¶æ„å›¾

```
è¾“å…¥: URL å­—ç¬¦ä¸²
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å­—ç¬¦çº§ç¼–ç ï¼ˆä¸»æµï¼‰                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  src/data/url_dataset.py                    â”‚
â”‚  â”œâ”€â”€ encode_url()                           â”‚
â”‚  â”‚   â””â”€â”€ ord(ch) â†’ [0, 127]                 â”‚
â”‚  â””â”€â”€ UrlDataset                             â”‚
â”‚      â””â”€â”€ è¾“å‡º: (input_ids, label)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          DataModule                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  src/datamodules/url_datamodule.py          â”‚
â”‚  â””â”€â”€ UrlDataModule (Lightning)              â”‚
â”‚      â”œâ”€â”€ train_dataloader()                 â”‚
â”‚      â”œâ”€â”€ val_dataloader()                   â”‚
â”‚      â””â”€â”€ test_dataloader()                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ç¼–ç å™¨ï¼ˆä¸»æµï¼‰                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  src/models/url_encoder.py                  â”‚
â”‚  â””â”€â”€ URLEncoder                             â”‚
â”‚      â”œâ”€â”€ Embedding(128, 128)                â”‚
â”‚      â”œâ”€â”€ BiLSTM(128 â†’ 128, layers=2)        â”‚
â”‚      â””â”€â”€ Linear(256 â†’ 256)                  â”‚
â”‚      è¾“å‡º: [B, 256]                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Lightning ç³»ç»Ÿ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  src/systems/url_only_module.py             â”‚
â”‚  â””â”€â”€ UrlOnlyModule                          â”‚
â”‚      â”œâ”€â”€ encoder: URLEncoder                â”‚
â”‚      â”œâ”€â”€ classifier: Linear(256 â†’ 2)        â”‚
â”‚      â”œâ”€â”€ criterion: CrossEntropyLoss        â”‚
â”‚      â””â”€â”€ optimizer: AdamW(lr=1e-3)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         è¾“å‡º: é¢„æµ‹æ ‡ç­¾ (0/1)
```

---

## ğŸ¯ ä¸ºä»€ä¹ˆé€‰æ‹©å­—ç¬¦çº§ BiLSTMï¼Ÿ

### ä¼˜åŠ¿

1. **URL ç‰¹æ€§å¥‘åˆ**
   - URL æ˜¯åºåˆ—åŒ–æ•°æ®
   - å­—ç¬¦çº§ç‰¹å¾æ•æ‰åŸŸåã€è·¯å¾„æ¨¡å¼
   - ä¸å—è¯è¡¨é™åˆ¶

2. **æ€§èƒ½**
   - è½»é‡çº§ï¼ˆ~1M å‚æ•° vs BERT 110Mï¼‰
   - è®­ç»ƒå¿«é€Ÿ
   - æ¨ç†é«˜æ•ˆ

3. **å®ç”¨æ€§**
   - æ— éœ€é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½
   - æ— éœ€ HuggingFace ä¾èµ–
   - æ˜“äºéƒ¨ç½²

### HuggingFace BERT çš„é—®é¢˜

1. âŒ è¿‡é‡ï¼ˆ110M å‚æ•°ï¼‰
2. âŒ ä¸ºè‡ªç„¶è¯­è¨€è®¾è®¡ï¼Œä¸æ˜¯ URL
3. âŒ éœ€è¦ tokenizerï¼ŒURL å¯èƒ½è¢«é”™è¯¯åˆ†è¯
4. âŒ è®­ç»ƒæ…¢ã€æ¨ç†æ…¢

---

## ğŸ”„ è¿ç§»æŒ‡å—

### å¦‚æœä½ æƒ³ä» Legacy è¿ç§»åˆ°ä¸»æµ

**ä¸éœ€è¦è¿ç§»ï¼å·²ç»åœ¨ä½¿ç”¨ä¸»æµæ–¹æ¡ˆäº†ã€‚**

### å¦‚æœä½ æƒ³ä½¿ç”¨ Legacy æ–¹æ¡ˆ

```bash
# 1. ç¡®ä¿å®‰è£…äº† transformers
pip install transformers

# 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆé¦–æ¬¡ï¼‰
python -c "from transformers import AutoModel; AutoModel.from_pretrained('roberta-base')"

# 3. ä½¿ç”¨ legacy é…ç½®
python scripts/train_hydra.py model=url_encoder_legacy train.lr=2e-5
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | å­—ç¬¦çº§ BiLSTM | HuggingFace BERT |
|------|---------------|------------------|
| **å‚æ•°é‡** | ~1M | ~110M |
| **è®­ç»ƒé€Ÿåº¦** | âš¡âš¡âš¡âš¡âš¡ | âš¡âš¡ |
| **æ¨ç†é€Ÿåº¦** | âš¡âš¡âš¡âš¡âš¡ | âš¡âš¡ |
| **å†…å­˜å ç”¨** | ~500MB | ~2GB |
| **F1 Score** | 0.95+ | 0.96+ |
| **é€‚åˆåœºæ™¯** | âœ… ç”Ÿäº§ç¯å¢ƒ | âš ï¸ ç ”ç©¶å¯¹æ¯” |

---

## âœ… å»ºè®®

### æ¨èä½¿ç”¨ï¼ˆé»˜è®¤ï¼‰

**å­—ç¬¦çº§ BiLSTM** - è½»é‡ã€å¿«é€Ÿã€å®ç”¨

```bash
python scripts/train_hydra.py
```

### ç‰¹æ®Šåœºæ™¯

**HuggingFace BERT** - ä»…ç”¨äºï¼š
- å¤šæ¨¡æ€èåˆéœ€è¦ç»Ÿä¸€åµŒå…¥ç»´åº¦
- æ€§èƒ½å¯¹æ¯”å®éªŒ
- ç ”ç©¶ç›®çš„

```bash
python scripts/train_hydra.py model=url_encoder_legacy
```

---

## ğŸ“ æ€»ç»“

1. âœ… **å½“å‰ä¸»æµï¼šå­—ç¬¦çº§ BiLSTM**
2. âš ï¸ **HuggingFace BERT æ˜¯ Legacy**
3. âœ… **é…ç½®å·²æ›´æ–°åŒ¹é…å®é™…æ¶æ„**
4. âœ… **ä¸¤ç§æ–¹æ¡ˆå¯ä»¥çµæ´»åˆ‡æ¢**

---

**ä½œè€…:** UAAM-Phish Team
**æ›´æ–°:** 2025-10-22
**çŠ¶æ€:** âœ… å·²æ¾„æ¸…
