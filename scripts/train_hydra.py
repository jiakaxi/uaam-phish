"""
ä½¿ç”¨ Hydra é…ç½®ç®¡ç†çš„è®­ç»ƒè„šæœ¬
æ”¯æŒå‘½ä»¤è¡Œè¦†ç›–å’Œå¤šè¿è¡Œå®éªŒ

ç”¨æ³•:
    # ä½¿ç”¨é»˜è®¤é…ç½®
    python scripts/train_hydra.py

    # ä½¿ç”¨ç‰¹å®š trainer
    python scripts/train_hydra.py trainer=local
    python scripts/train_hydra.py trainer=server

    # ä½¿ç”¨å®éªŒé…ç½®
    python scripts/train_hydra.py experiment=url_baseline

    # å‘½ä»¤è¡Œè¦†ç›–å‚æ•°
    python scripts/train_hydra.py trainer=server train.bs=64 model.dropout=0.3

    # å¤šè¿è¡Œè¶…å‚æ•°æœç´¢
    python scripts/train_hydra.py -m train.lr=1e-5,2e-5,5e-5 model.dropout=0.1,0.2,0.3
"""

import hydra
from omegaconf import DictConfig, OmegaConf
from pathlib import Path
import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping

from src.utils.seed import set_global_seed
from src.systems.url_only_module import UrlOnlySystem
from src.datamodules.url_datamodule import UrlDataModule
from src.utils.experiment_tracker import ExperimentTracker
from src.utils.callbacks import ExperimentResultsCallback, TestPredictionCollector
from src.utils.logging import get_logger

log = get_logger(__name__)


@hydra.main(config_path="../configs", config_name="config", version_base="1.3")
def train(cfg: DictConfig) -> float:
    """
    Hydra è®­ç»ƒä¸»å‡½æ•°

    Args:
        cfg: Hydra é…ç½®å¯¹è±¡

    Returns:
        æµ‹è¯•é›†æœ€ä½³æŒ‡æ ‡ï¼ˆç”¨äºè¶…å‚æ•°ä¼˜åŒ–ï¼‰
    """
    # æ‰“å°é…ç½®ï¼ˆè°ƒè¯•ç”¨ï¼‰
    log.info("=" * 70)
    log.info("é…ç½®å†…å®¹:")
    log.info(OmegaConf.to_yaml(cfg))
    log.info("=" * 70)

    # è®¾ç½®éšæœºç§å­
    pl.seed_everything(cfg.run.seed, workers=True)
    set_global_seed(cfg.run.seed)
    try:
        torch.set_float32_matmul_precision("high")
    except Exception:
        pass

    # åˆå§‹åŒ–å®éªŒè·Ÿè¸ªå™¨
    exp_tracker = None
    if not cfg.get("no_save", False):
        exp_tracker = ExperimentTracker(cfg, exp_name=cfg.run.name)
        log.info(f"\nğŸ“ å®éªŒç›®å½•: {exp_tracker.exp_dir}\n")

    # åˆå§‹åŒ–æ•°æ®å’Œæ¨¡å‹
    dm = UrlDataModule(cfg)
    model = UrlOnlySystem(cfg)

    # é…ç½®å›è°ƒ
    monitor = cfg.eval.get("monitor", "val_loss")
    patience = cfg.eval.get("patience", 3)
    mode = "max" if "f1" in monitor or "auroc" in monitor or "acc" in monitor else "min"

    callbacks = [
        EarlyStopping(monitor=monitor, mode=mode, patience=patience),
        ModelCheckpoint(
            monitor=monitor,
            mode=mode,
            save_top_k=1,
            filename=f"best-{{epoch}}-{{{monitor.replace('/', '_')}:.3f}}",
        ),
    ]

    # æ·»åŠ å®éªŒç»“æœä¿å­˜å›è°ƒ
    if exp_tracker:
        callbacks.append(ExperimentResultsCallback(exp_tracker))
        pred_collector = TestPredictionCollector()
        callbacks.append(pred_collector)

    # é…ç½® Logger
    logger = None
    if "logger" in cfg:
        try:
            logger = hydra.utils.instantiate(cfg.logger)
            log.info(f"âœ… ä½¿ç”¨ Logger: {cfg.logger._target_}")
        except Exception as e:
            log.warning(f"âš ï¸  Logger åˆå§‹åŒ–å¤±è´¥: {e}")
            log.warning("   å°†ä½¿ç”¨é»˜è®¤çš„ CSV logger")

    # é…ç½®è®­ç»ƒå™¨
    trainer = pl.Trainer(
        max_epochs=cfg.train.epochs,
        accelerator=cfg.hardware.accelerator,
        devices=cfg.hardware.devices,
        precision=cfg.hardware.precision,
        strategy=cfg.hardware.get("strategy", "auto"),
        log_every_n_steps=cfg.train.log_every,
        callbacks=callbacks,
        logger=logger,
        gradient_clip_val=1.0,
    )

    # æ‰“å°è®­ç»ƒä¿¡æ¯
    log.info("=" * 70)
    log.info("ğŸš€ å¼€å§‹è®­ç»ƒ")
    log.info("=" * 70)
    log.info("ğŸ“Š æ¨¡å‹é…ç½®:")
    log.info(f"  - é¢„è®­ç»ƒæ¨¡å‹: {cfg.model.pretrained_name}")
    log.info(f"  - æœ€å¤§é•¿åº¦: {cfg.data.max_length}")
    log.info(f"  - Dropout: {cfg.model.dropout}")
    log.info("\nğŸ”§ è®­ç»ƒé…ç½®:")
    log.info(f"  - Epochs: {cfg.train.epochs}")
    log.info(f"  - Batch size: {cfg.train.bs}")
    log.info(f"  - Learning rate: {cfg.train.lr}")
    log.info(f"  - é‡‡æ ·æ¯”ä¾‹: {cfg.data.sample_fraction}")
    log.info("\nğŸ’» ç¡¬ä»¶é…ç½®:")
    log.info(f"  - Accelerator: {cfg.hardware.accelerator}")
    log.info(f"  - Devices: {cfg.hardware.devices}")
    log.info(f"  - Precision: {cfg.hardware.precision}")
    log.info("\nğŸ“ˆ ç›‘æ§é…ç½®:")
    log.info(f"  - Monitor: {monitor}")
    log.info(f"  - Mode: {mode}")
    log.info(f"  - Patience: {patience}")
    log.info("=" * 70 + "\n")

    # è®­ç»ƒå’Œæµ‹è¯•
    trainer.fit(model, dm)
    test_results = trainer.test(
        model, dataloaders=dm.test_dataloader(), ckpt_path="best"
    )

    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    if exp_tracker and not cfg.get("no_save", False):
        try:
            from src.utils.visualizer import ResultVisualizer

            lightning_log_dir = Path(trainer.log_dir)
            metrics_csv = lightning_log_dir / "metrics.csv"
            y_true, y_prob = pred_collector.get_predictions()

            if len(y_true) > 0 and metrics_csv.exists():
                log.info("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                ResultVisualizer.create_all_plots(
                    metrics_csv=metrics_csv,
                    y_true=y_true,
                    y_prob=y_prob,
                    output_dir=exp_tracker.results_dir,
                )
                log.info("âœ… æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆ\n")
        except ImportError:
            log.warning("âš ï¸  matplotlib/seaborn æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
            log.warning('   å®‰è£…å‘½ä»¤: pip install -e ".[viz]"')
        except Exception as e:
            log.warning(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")

    log.info("\n" + "=" * 70)
    log.info("âœ… è®­ç»ƒå®Œæˆï¼")
    if exp_tracker:
        log.info(f"ğŸ“ å®éªŒç»“æœä¿å­˜åœ¨: {exp_tracker.exp_dir}")
    log.info("=" * 70)

    # è¿”å›æœ€ä½³æŒ‡æ ‡ï¼ˆç”¨äºè¶…å‚æ•°ä¼˜åŒ–ï¼‰
    if test_results:
        best_metric = test_results[0].get(f"test/{monitor.split('/')[-1]}", 0.0)
        return float(best_metric)
    return 0.0


if __name__ == "__main__":
    train()
