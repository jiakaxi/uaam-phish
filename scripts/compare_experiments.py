#!/usr/bin/env python
"""
å®éªŒå¯¹æ¯”å·¥å…·
å¿«é€Ÿå¯¹æ¯”å¤šä¸ªå®éªŒçš„ç»“æœ
"""
import argparse
import json
from pathlib import Path
from typing import List, Dict
import pandas as pd


def load_experiment_metrics(exp_dir: Path) -> Dict:
    """åŠ è½½å®éªŒæŒ‡æ ‡"""
    metrics_file = exp_dir / "results" / "metrics_final.json"
    config_file = exp_dir / "config.yaml"
    
    result = {
        "å®éªŒåç§°": exp_dir.name,
        "å®éªŒç›®å½•": str(exp_dir),
    }
    
    # åŠ è½½æŒ‡æ ‡
    if metrics_file.exists():
        with open(metrics_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            metrics = data.get('metrics', {})
            
            # æå–å…³é”®æŒ‡æ ‡
            for key, value in metrics.items():
                clean_key = key.replace('/', '_').replace('test_', '')
                if isinstance(value, float):
                    result[clean_key] = round(value, 4)
                else:
                    result[clean_key] = value
    else:
        result["çŠ¶æ€"] = "âŒ æŒ‡æ ‡æ–‡ä»¶ç¼ºå¤±"
    
    # åŠ è½½é…ç½®ï¼ˆå¯é€‰ï¼‰
    if config_file.exists():
        try:
            from omegaconf import OmegaConf
            cfg = OmegaConf.load(config_file)
            result["æ¨¡å‹"] = cfg.model.pretrained_name
            result["å­¦ä¹ ç‡"] = cfg.train.lr
            result["æ‰¹é‡å¤§å°"] = cfg.train.bs
            result["Dropout"] = cfg.model.dropout
        except Exception:
            pass
            
    return result


def compare_experiments(exp_dirs: List[Path], output_file: str = None) -> pd.DataFrame:
    """
    å¯¹æ¯”å¤šä¸ªå®éªŒ
    
    Args:
        exp_dirs: å®éªŒç›®å½•åˆ—è¡¨
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        å¯¹æ¯”ç»“æœ DataFrame
    """
    results = []
    
    for exp_dir in exp_dirs:
        if not exp_dir.exists():
            print(f"âš ï¸  å®éªŒç›®å½•ä¸å­˜åœ¨: {exp_dir}")
            continue
            
        try:
            metrics = load_experiment_metrics(exp_dir)
            results.append(metrics)
        except Exception as e:
            print(f"âš ï¸  åŠ è½½å®éªŒå¤±è´¥ {exp_dir.name}: {e}")
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å®éªŒ")
        return None
    
    # åˆ›å»º DataFrame
    df = pd.DataFrame(results)
    
    # æŒ‰ F1 æˆ– AUROC æ’åºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'f1' in df.columns:
        df = df.sort_values('f1', ascending=False)
    elif 'auroc' in df.columns:
        df = df.sort_values('auroc', ascending=False)
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 100)
    print("å®éªŒå¯¹æ¯”ç»“æœ")
    print("=" * 100)
    print(df.to_string(index=False))
    print("=" * 100)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    if output_file:
        output_path = Path(output_file)
        if output_path.suffix == '.csv':
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
        elif output_path.suffix == '.xlsx':
            df.to_excel(output_path, index=False)
        elif output_path.suffix == '.md':
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("# å®éªŒå¯¹æ¯”ç»“æœ\n\n")
                f.write(df.to_markdown(index=False))
        else:
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    return df


def find_latest_experiments(base_dir: Path, n: int = 5) -> List[Path]:
    """æŸ¥æ‰¾æœ€è¿‘çš„ N ä¸ªå®éªŒ"""
    exp_dirs = [d for d in base_dir.iterdir() if d.is_dir()]
    exp_dirs.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return exp_dirs[:n]


def find_best_experiment(base_dir: Path, metric: str = 'f1') -> Path:
    """æŸ¥æ‰¾æœ€ä½³å®éªŒ"""
    best_exp = None
    best_value = -float('inf')
    
    for exp_dir in base_dir.iterdir():
        if not exp_dir.is_dir():
            continue
            
        metrics_file = exp_dir / "results" / "metrics_final.json"
        if not metrics_file.exists():
            continue
            
        try:
            with open(metrics_file, 'r') as f:
                data = json.load(f)
                metrics = data.get('metrics', {})
                
                # æŸ¥æ‰¾æŒ‡å®šæŒ‡æ ‡
                value = None
                for key in metrics:
                    if metric in key.lower():
                        value = metrics[key]
                        break
                
                if value is not None and value > best_value:
                    best_value = value
                    best_exp = exp_dir
        except Exception:
            continue
    
    return best_exp


def main():
    parser = argparse.ArgumentParser(description="å®éªŒå¯¹æ¯”å·¥å…·")
    parser.add_argument("--base_dir", default="experiments", help="å®éªŒæ ¹ç›®å½•")
    parser.add_argument("--exp_names", nargs='+', help="è¦å¯¹æ¯”çš„å®éªŒåç§°åˆ—è¡¨")
    parser.add_argument("--latest", type=int, help="å¯¹æ¯”æœ€è¿‘çš„ N ä¸ªå®éªŒ")
    parser.add_argument("--all", action="store_true", help="å¯¹æ¯”æ‰€æœ‰å®éªŒ")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (.csv, .xlsx, .md)")
    parser.add_argument("--metric", default="f1", help="æ’åºæŒ‡æ ‡")
    parser.add_argument("--find_best", action="store_true", help="æŸ¥æ‰¾æœ€ä½³å®éªŒ")
    
    args = parser.parse_args()
    
    base_dir = Path(args.base_dir)
    
    if not base_dir.exists():
        print(f"âŒ å®éªŒç›®å½•ä¸å­˜åœ¨: {base_dir}")
        return
    
    # æŸ¥æ‰¾æœ€ä½³å®éªŒ
    if args.find_best:
        best_exp = find_best_experiment(base_dir, args.metric)
        if best_exp:
            print(f"ğŸ† æœ€ä½³å®éªŒ (æŒ‰ {args.metric}): {best_exp.name}")
            metrics = load_experiment_metrics(best_exp)
            print("\næŒ‡æ ‡:")
            for key, value in metrics.items():
                print(f"  {key}: {value}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å®éªŒç»“æœ")
        return
    
    # ç¡®å®šè¦å¯¹æ¯”çš„å®éªŒ
    exp_dirs = []
    
    if args.exp_names:
        # æŒ‡å®šå®éªŒåç§°
        for name in args.exp_names:
            exp_dir = base_dir / name
            if exp_dir.exists():
                exp_dirs.append(exp_dir)
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                matched = [d for d in base_dir.iterdir() 
                          if d.is_dir() and name in d.name]
                if matched:
                    exp_dirs.extend(matched)
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°å®éªŒ: {name}")
    
    elif args.latest:
        # æœ€è¿‘çš„ N ä¸ªå®éªŒ
        exp_dirs = find_latest_experiments(base_dir, args.latest)
        print(f"ğŸ“Š å¯¹æ¯”æœ€è¿‘çš„ {len(exp_dirs)} ä¸ªå®éªŒ:")
        for exp in exp_dirs:
            print(f"  - {exp.name}")
        print()
    
    elif args.all:
        # æ‰€æœ‰å®éªŒ
        exp_dirs = [d for d in base_dir.iterdir() if d.is_dir()]
        print(f"ğŸ“Š å¯¹æ¯”æ‰€æœ‰ {len(exp_dirs)} ä¸ªå®éªŒ\n")
    
    else:
        # é»˜è®¤ï¼šæœ€è¿‘çš„ 5 ä¸ªå®éªŒ
        exp_dirs = find_latest_experiments(base_dir, 5)
        print(f"ğŸ“Š å¯¹æ¯”æœ€è¿‘çš„ {len(exp_dirs)} ä¸ªå®éªŒ (ä½¿ç”¨ --latest N æˆ– --all ä¿®æ”¹):")
        for exp in exp_dirs:
            print(f"  - {exp.name}")
        print()
    
    if not exp_dirs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¦å¯¹æ¯”çš„å®éªŒ")
        print("æç¤º:")
        print("  - ä½¿ç”¨ --exp_names exp1 exp2 æŒ‡å®šå®éªŒ")
        print("  - ä½¿ç”¨ --latest 10 å¯¹æ¯”æœ€è¿‘ 10 ä¸ªå®éªŒ")
        print("  - ä½¿ç”¨ --all å¯¹æ¯”æ‰€æœ‰å®éªŒ")
        return
    
    # æ‰§è¡Œå¯¹æ¯”
    df = compare_experiments(exp_dirs, output_file=args.output)
    
    # æ˜¾ç¤ºæœ€ä½³å®éªŒ
    if df is not None and len(df) > 0:
        print(f"\nğŸ† å½“å‰å¯¹æ¯”ä¸­çš„æœ€ä½³å®éªŒ:")
        best_row = df.iloc[0]
        print(f"  å®éªŒ: {best_row['å®éªŒåç§°']}")
        if args.metric in df.columns:
            print(f"  {args.metric}: {best_row[args.metric]}")


if __name__ == "__main__":
    main()

