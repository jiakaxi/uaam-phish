import argparse
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from omegaconf import OmegaConf
from pathlib import Path
import torch

from src.utils.seed import set_global_seed
from src.systems.url_only_module import UrlOnlySystem
from src.datamodules.url_datamodule import UrlDataModule
from src.utils.experiment_tracker import ExperimentTracker
from src.utils.callbacks import ExperimentResultsCallback, TestPredictionCollector
from src.utils.logging import get_logger

set_global_seed(3407)
log = get_logger(__name__)
log.info("Training start")


if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--profile", default=None, choices=[None, "local", "server"])
    ap.add_argument("--exp_name", default=None, help="å®éªŒåç§°ï¼ˆå¯é€‰ï¼‰")
    ap.add_argument("--no_save", action="store_true", help="ä¸ä¿å­˜å®éªŒç»“æœ")
    args = ap.parse_args()

    # åŠ è½½é…ç½®
    cfg = OmegaConf.load("configs/default.yaml")
    if args.profile:
        prof = OmegaConf.load(f"configs/profiles/{args.profile}.yaml")
        cfg = OmegaConf.merge(cfg, prof)

    # è®¾ç½®éšæœºç§å­
    set_global_seed(cfg.train.seed)
    try:
        torch.set_float32_matmul_precision("high")
    except Exception:
        pass

    # åˆå§‹åŒ–å®éªŒè·Ÿè¸ªå™¨
    exp_tracker = None
    if not args.no_save:
        exp_tracker = ExperimentTracker(cfg, exp_name=args.exp_name)
        print(f"\nğŸ“ å®éªŒç›®å½•: {exp_tracker.exp_dir}\n")

    # åˆå§‹åŒ–æ•°æ®å’Œæ¨¡å‹
    dm = UrlDataModule(cfg)
    model = UrlOnlySystem(cfg)

    # é…ç½®å›è°ƒ
    monitor = cfg.eval.get("monitor", "val/loss")
    patience = cfg.eval.get("patience", 3)
    mode = "max" if "f1" in monitor or "auroc" in monitor else "min"

    callbacks = [
        EarlyStopping(monitor=monitor, mode=mode, patience=patience),
        ModelCheckpoint(
            monitor=monitor,
            mode=mode,
            save_top_k=1,
            filename=f"best-{{epoch}}-{{{monitor.replace('/', '_')}:.3f}}",
        ),
    ]

    # æ·»åŠ å®éªŒç»“æœä¿å­˜å›è°ƒ
    if exp_tracker:
        callbacks.append(ExperimentResultsCallback(exp_tracker))
        # æ·»åŠ é¢„æµ‹æ”¶é›†å™¨ï¼ˆç”¨äºç”Ÿæˆ ROC æ›²çº¿ç­‰ï¼‰
        pred_collector = TestPredictionCollector()
        callbacks.append(pred_collector)

    # é…ç½®è®­ç»ƒå™¨
    trainer = pl.Trainer(
        max_epochs=cfg.train.epochs,
        accelerator=cfg.hardware.accelerator,
        devices=cfg.hardware.devices,
        precision=cfg.hardware.precision,
        strategy=cfg.hardware.get("strategy", "auto"),
        log_every_n_steps=cfg.train.log_every,
        callbacks=callbacks,
        gradient_clip_val=1.0,
    )

    # æ‰“å°é…ç½®ä¿¡æ¯
    print("=" * 70)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ")
    print("=" * 70)
    print("ğŸ“Š æ¨¡å‹é…ç½®:")
    print(f"  - é¢„è®­ç»ƒæ¨¡å‹: {cfg.model.pretrained_name}")
    print(f"  - æœ€å¤§é•¿åº¦: {cfg.data.max_length}")
    print(f"  - Dropout: {cfg.model.dropout}")
    print("\nğŸ”§ è®­ç»ƒé…ç½®:")
    print(f"  - Epochs: {cfg.train.epochs}")
    print(f"  - Batch size: {cfg.train.bs}")
    print(f"  - Learning rate: {cfg.train.lr}")
    print(f"  - é‡‡æ ·æ¯”ä¾‹: {cfg.data.sample_fraction}")
    print("\nğŸ’» ç¡¬ä»¶é…ç½®:")
    print(f"  - Accelerator: {cfg.hardware.accelerator}")
    print(f"  - Devices: {cfg.hardware.devices}")
    print(f"  - Precision: {cfg.hardware.precision}")
    print("\nğŸ“ˆ ç›‘æ§é…ç½®:")
    print(f"  - Monitor: {monitor}")
    print(f"  - Mode: {mode}")
    print(f"  - Patience: {patience}")
    print("=" * 70)
    print()

    # è®­ç»ƒå’Œæµ‹è¯•
    trainer.fit(model, dm)
    test_results = trainer.test(
        model, dataloaders=dm.test_dataloader(), ckpt_path="best"
    )

    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆå¦‚æœå®‰è£…äº† matplotlibï¼‰
    if exp_tracker and not args.no_save:
        try:
            from src.utils.visualizer import ResultVisualizer

            # è·å– Lightning æ—¥å¿—ç›®å½•
            lightning_log_dir = Path(trainer.log_dir)
            metrics_csv = lightning_log_dir / "metrics.csv"

            # è·å–æµ‹è¯•é›†é¢„æµ‹
            y_true, y_prob = pred_collector.get_predictions()

            if len(y_true) > 0 and metrics_csv.exists():
                print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                ResultVisualizer.create_all_plots(
                    metrics_csv=metrics_csv,
                    y_true=y_true,
                    y_prob=y_prob,
                    output_dir=exp_tracker.results_dir,
                )
                print("âœ… æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆ\n")
        except ImportError:
            print("âš ï¸  matplotlib/seaborn æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
            print('   å®‰è£…å‘½ä»¤: pip install -e ".[viz]"')
        except Exception as e:
            print(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")

    print("\n" + "=" * 70)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    if exp_tracker:
        print(f"ğŸ“ å®éªŒç»“æœä¿å­˜åœ¨: {exp_tracker.exp_dir}")
    print("=" * 70)
