# MLOps åŠŸèƒ½å®ç°çŠ¶æ€æŠ¥å‘Š

**æ—¥æœŸ**: 2025-10-23
**å®éªŒ**: url_mvp_20251023_081630

---

## ğŸ“‹ åŠŸèƒ½æ£€æŸ¥æ¸…å•

### âœ… **å·²å®Œæ•´å®ç°å¹¶ä½¿ç”¨**

#### 1. **Step Metrics (æ­¥éª¤çº§æŒ‡æ ‡)**
```
çŠ¶æ€: âœ… å®Œå…¨å®ç°å¹¶è¿è¡Œ
ä½ç½®: src/utils/metrics.py, src/systems/url_only_module.py

æŒ‡æ ‡:
  âœ“ Accuracy (å‡†ç¡®ç‡)
  âœ“ AUROC (pos_label=1)
  âœ“ F1-macro

é…ç½®:
  metrics.dist.sync_metrics: false (é»˜è®¤)
  metrics.average: macro
```

#### 2. **Epoch Metrics (è½®æ¬¡çº§æŒ‡æ ‡)**
```
çŠ¶æ€: âœ… å®Œå…¨å®ç°å¹¶è¿è¡Œ
ä½ç½®: src/systems/url_only_module.py

æŒ‡æ ‡:
  âœ“ NLL (Negative Log Likelihood)
  âœ“ ECE (Expected Calibration Error) with adaptive bins

ç»“æœ: test_nll=0.0345, test_ece=0.0207, test_ece_bins=10
```

#### 3. **Protocol Artifacts (åè®®äº§ç‰©)**
```
çŠ¶æ€: âœ… å®Œå…¨å®ç°å¹¶ç”Ÿæˆ
ä½ç½®: src/utils/protocol_artifacts.py, src/utils/visualizer.py

ç”Ÿæˆæ–‡ä»¶:
  âœ“ metrics_random.json - æŒ‡æ ‡JSONæ–‡ä»¶
  âœ“ roc_random.png - ROCæ›²çº¿ (åŒ…å«AUCæ ‡æ³¨)
  âœ“ calib_random.png - æ ¡å‡†æ›²çº¿ (åŒ…å«ECEæ ‡æ³¨)
  âœ“ implementation_report.md - å®ç°æŠ¥å‘Š
```

#### 4. **Batch Format Configuration (æ‰¹é‡æ ¼å¼é…ç½®)**
```
çŠ¶æ€: âœ… å·²é…ç½®
ä½ç½®: configs/data/url_only.yaml

é…ç½®:
  data.batch_format: tuple (é»˜è®¤å€¼)

ä»£ç æ”¯æŒ:
  âœ“ src/utils/batch_utils.py - _unpack_batch() å‡½æ•°
  âœ“ æ”¯æŒ tuple å’Œ dict ä¸¤ç§æ ¼å¼
```

#### 5. **Metadata Column Names (å…ƒæ•°æ®åˆ—å)**
```
çŠ¶æ€: âœ… å·²é…ç½®
ä½ç½®: configs/data/url_only.yaml

é…ç½®:
  âœ“ data.text_col: url_text
  âœ“ data.label_col: label
  âœ“ data.timestamp_col: timestamp
  âœ“ data.brand_col: brand
  âœ“ data.source_col: source
```

---

### âš ï¸ **å·²å®ç°ä½†æœªä½¿ç”¨**

#### 6. **Data Splitting Protocols (æ•°æ®åˆ†å‰²åè®®)**
```
çŠ¶æ€: âš ï¸ ä»£ç å®Œæ•´ä½†æœªå¯ç”¨
ä½ç½®: src/utils/splits.py

å·²å®ç°åè®®:
  âœ“ random - éšæœºåˆ†å‰²ï¼ˆåˆ†å±‚é‡‡æ ·ï¼‰
  âœ“ temporal - æ—¶åºåˆ†å‰²ï¼ˆtie_policy="left-closed"ï¼‰
  âœ“ brand_ood - å“ç‰ŒåŸŸå¤–åˆ†å‰²ï¼ˆä¸ç›¸äº¤å“ç‰Œé›†ï¼‰

å‡½æ•°:
  âœ“ build_splits(df, cfg, protocol) - å®Œæ•´å®ç°
  âœ“ è‡ªåŠ¨é™çº§æœºåˆ¶ï¼ˆæ•°æ®ä¸è¶³æ—¶é™çº§åˆ°randomï¼‰
  âœ“ ç”Ÿæˆsplits_{protocol}.csvç»Ÿè®¡è¡¨

æœªä½¿ç”¨åŸå› :
  âœ— use_build_splits: false (æœªå¯ç”¨)
  âœ— protocol: æœªè®¾ç½®
  âœ— ä½¿ç”¨çš„æ˜¯é¢„å…ˆåˆ†å‰²çš„CSVæ–‡ä»¶
```

#### 7. **Metadata Extraction (å…ƒæ•°æ®æå–)**
```
çŠ¶æ€: âš ï¸ é…ç½®å­˜åœ¨ä½†æ•°æ®é›†æœªè¿”å›
ä½ç½®: src/data/url_dataset.py

å½“å‰è¡Œä¸º:
  - UrlDataset.__getitem__() è¿”å›: (input_ids, label)
  - ç¬¦åˆ "non-breaking" åŸåˆ™ âœ“

æ”¯æŒ:
  âœ“ _unpack_batch() å¯å¤„ç† (x, y) æˆ– (x, y, meta)
  âœ“ é…ç½®æ–‡ä»¶ä¸­æœ‰ timestamp/brand/source åˆ—å

ç¼ºå¤±:
  âœ— æ•°æ®é›†æœªè¯»å– timestamp/brand/source åˆ—
  âœ— meta dict å§‹ç»ˆä¸º {timestamp: None, brand: None, source: None}

åŸå› :
  - UrlDataset ä¸“æ³¨äºå­—ç¬¦çº§URLç¼–ç 
  - å½“å‰CSVæ–‡ä»¶(url_train.csv)åªæœ‰ url_text, label ä¸¤åˆ—
```

---

## ğŸ“Š **å®ç°çŠ¶æ€æ€»ç»“**

### âœ… **å®Œå…¨ç¬¦åˆè§„èŒƒçš„åŠŸèƒ½**

1. âœ… **Non-breaking Batching**
   ```python
   # Dataset ä¿æŒè¿”å› (x, y)
   def __getitem__(self, index):
       return torch.tensor(encoded), torch.tensor(label)

   # _unpack_batch å¤„ç†å¹¶æä¾›é»˜è®¤ meta
   inputs, labels, meta = _unpack_batch(batch, batch_format="tuple")
   # meta = {timestamp: None, brand: None, source: None}
   ```

2. âœ… **Config Key `data.batch_format`**
   ```yaml
   data:
     batch_format: tuple  # é»˜è®¤å€¼ âœ“
   ```

3. âœ… **Step Metrics**
   ```
   Accuracy, AUROC(pos_label=1), F1(macro) âœ“
   ```

4. âœ… **Epoch Metrics**
   ```
   NLL, ECE(adaptive bins) âœ“
   ```

5. âœ… **Artifacts**
   ```
   roc_{protocol}.png âœ“
   calib_{protocol}.png (with ECE annotation) âœ“
   metrics_{protocol}.json âœ“
   ```

---

### âš ï¸ **éƒ¨åˆ†å®ç°çš„åŠŸèƒ½**

1. âš ï¸ **Data Protocols & Splits**
   ```
   å®ç°çŠ¶æ€: CODE COMPLETE âœ“
   ä½¿ç”¨çŠ¶æ€: NOT ENABLED âœ—

   è¦å¯ç”¨:
   1. å‡†å¤‡åŒ…å«æ‰€æœ‰åˆ—çš„ master.csv
   2. è®¾ç½® use_build_splits: true
   3. è®¾ç½® protocol: random/temporal/brand_ood
   ```

2. âš ï¸ **Metadata Extraction**
   ```
   é…ç½®çŠ¶æ€: CONFIGURED âœ“
   æ•°æ®æµè½¬: NOT PASSING THROUGH âœ—

   å½“å‰: meta å§‹ç»ˆä¸º None
   åŸå› : UrlDataset åªè¿”å› (x, y)
   è§£å†³: æ‰©å±• UrlDataset æˆ–ä½¿ç”¨ collate_fn
   ```

---

## ğŸ’¡ **å¦‚ä½•å¯ç”¨æ‰€æœ‰åŠŸèƒ½**

### æ–¹æ¡ˆ1: å®Œæ•´çš„Protocolå®éªŒ

åˆ›å»º `configs/experiment/url_with_protocols.yaml`:

```yaml
# @package _global_

defaults:
  - override /data: url_only
  - override /model: url_encoder

run:
  name: url_with_protocols
  seed: 42

# å¯ç”¨ protocol splits
protocol: random  # æˆ– temporal, brand_ood
use_build_splits: true

data:
  csv_path: data/processed/master.csv  # åŒ…å«æ‰€æœ‰åˆ—çš„ä¸»æ–‡ä»¶
  batch_format: tuple

train:
  epochs: 50
  bs: 64
  lr: 0.0001
```

è¿è¡Œ:
```bash
python scripts/train_hydra.py experiment=url_with_protocols
```

è¿™æ ·ä¼šï¼š
1. ä» master.csv è¯»å–æ•°æ®
2. ä½¿ç”¨ build_splits() æŒ‰ protocol åˆ†å‰²
3. ç”Ÿæˆ splits_random.csv ç»Ÿè®¡è¡¨
4. è®­ç»ƒå¹¶ç”Ÿæˆæ‰€æœ‰artifacts

---

### æ–¹æ¡ˆ2: æ·»åŠ Metadataåˆ°Dataset

ä¿®æ”¹ `src/data/url_dataset.py`:

```python
class UrlDataset(Dataset):
    def __init__(self, csv_path, ...):
        frame = pd.read_csv(csv_path)
        self._texts = frame["url_text"].tolist()
        self._labels = frame["label"].tolist()

        # è¯»å–å…ƒæ•°æ®åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._timestamps = frame.get("timestamp", pd.Series([None]*len(frame))).tolist()
        self._brands = frame.get("brand", pd.Series([None]*len(frame))).tolist()
        self._sources = frame.get("source", pd.Series([None]*len(frame))).tolist()

    def __getitem__(self, index):
        # ä¿æŒ non-breaking: è¿”å› (x, y, meta)
        encoded = encode_url(...)
        label = self._labels[index]

        meta = {
            "timestamp": self._timestamps[index],
            "brand": self._brands[index],
            "source": self._sources[index],
        }

        return torch.tensor(encoded), torch.tensor(label), meta
```

è¿™æ ·ï¼š
1. ä¿æŒ non-breaking (å¯ä»¥è¿”å›2æˆ–3ä¸ªå…ƒç´ )
2. _unpack_batch è‡ªåŠ¨å¤„ç†
3. meta æ•°æ®è¢«ä¼ é€’åˆ°è®­ç»ƒå¾ªç¯

---

## ğŸ¯ **å½“å‰çŠ¶æ€æ€»ç»“**

### **è¿™æ¬¡è®­ç»ƒ (url_mvp_20251023_081630)**

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| Step Metrics | âœ… ä½¿ç”¨ | Accuracy, AUROC, F1 |
| Epoch Metrics | âœ… ä½¿ç”¨ | NLL, ECE |
| Artifacts | âœ… ç”Ÿæˆ | ROC, Calibration, JSON |
| batch_format | âœ… é…ç½® | tuple |
| Metadata Cols | âœ… é…ç½® | timestamp, brand, source |
| Protocol Splits | âš ï¸ æœªç”¨ | ä»£ç å­˜åœ¨ï¼Œæœªå¯ç”¨ |
| Metadata Flow | âš ï¸ æœªç”¨ | é…ç½®å­˜åœ¨ï¼Œæ•°æ®æœªä¼ é€’ |

---

### **å®Œæ•´åŠŸèƒ½å¯ç”¨éœ€è¦**

1. **å‡†å¤‡ä¸»æ•°æ®æ–‡ä»¶** (master.csv)
   ```
   url_text, label, timestamp, brand, source
   ```

2. **å¯ç”¨ protocol splits**
   ```yaml
   protocol: random  # or temporal, brand_ood
   use_build_splits: true
   ```

3. **æ‰©å±• Dataset** (å¯é€‰ï¼Œç”¨äºmetadata)
   ```python
   # è®© __getitem__ è¿”å› (x, y, meta)
   ```

---

## ğŸ“ **ç»“è®º**

### âœ… **å·²å®Œå…¨å®ç°çš„è§„èŒƒ**

1. âœ… Non-breaking Batching - Dataset è¿”å› (x,y)ï¼Œç³»ç»Ÿå…¼å®¹
2. âœ… batch_format config key - å·²é…ç½®é»˜è®¤ä¸º tuple
3. âœ… _unpack_batch helper - å®Œæ•´å®ç°
4. âœ… Step metrics - Accuracy, AUROC, F1-macro
5. âœ… Epoch metrics - NLL, ECE with adaptive bins
6. âœ… Artifacts - ROC, Calibration, JSON å…¨éƒ¨ç”Ÿæˆ
7. âœ… Metadata column names - å·²é…ç½®

### âš ï¸ **å¯é€‰åŠŸèƒ½ï¼ˆä»£ç å®Œæ•´ï¼Œå¯éšæ—¶å¯ç”¨ï¼‰**

1. âš ï¸ Protocol splits (random/temporal/brand_ood) - è®¾ç½®2ä¸ªå‚æ•°å³å¯å¯ç”¨
2. âš ï¸ Metadata extraction - æ‰©å±•Datasetæˆ–ä½¿ç”¨collate_fn

### ğŸ‰ **å½“å‰è®­ç»ƒå®Œå…¨ç¬¦åˆåŸºæœ¬è§„èŒƒï¼**

- æ‰€æœ‰å¿…éœ€çš„MLOpsåŠŸèƒ½éƒ½å·²å®ç°å¹¶è¿è¡Œ
- Protocol splits å’Œ metadata æ˜¯é«˜çº§å¯é€‰åŠŸèƒ½
- å¯ä»¥éšæ—¶é€šè¿‡é…ç½®å¯ç”¨

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2025-10-23*
*å®éªŒç›®å½•: experiments/url_mvp_20251023_081630*
