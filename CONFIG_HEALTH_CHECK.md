# é…ç½®å¥åº·æ£€æŸ¥ä¸æ‰©å±•è§„åˆ’

> **æ£€æŸ¥æ—¥æœŸ**: 2025-10-23
> **çŠ¶æ€**: âœ… é…ç½®å¥åº·ï¼Œå·²ä¸ºæœªæ¥æ‰©å±•åšå¥½å‡†å¤‡

---

## âœ… å½“å‰é…ç½®å¥åº·çŠ¶æ€

### 1. æ ¸å¿ƒé…ç½®æ£€æŸ¥

| é…ç½®é¡¹ | æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|--------|------|------|------|
| **ä¸»é…ç½®** | `configs/config.yaml` | âœ… æ­£å¸¸ | Hydra defaultsæ­£ç¡® |
| **é»˜è®¤é…ç½®** | `configs/default.yaml` | âœ… æ­£å¸¸ | æ‰€æœ‰å‚æ•°å®Œæ•´ |
| **æ¨¡å‹é…ç½®** | `configs/model/url_encoder.yaml` | âœ… æ­£å¸¸ | URLEncoderå‚æ•°æ­£ç¡® |
| **æ•°æ®é…ç½®** | `configs/data/url_only.yaml` | âœ… æ­£å¸¸ | æ”¯æŒç¯å¢ƒå˜é‡ |
| **è®­ç»ƒå™¨é…ç½®** | `configs/trainer/server.yaml` | âœ… æ­£å¸¸ | GPUé…ç½®åˆç† |
| **æ—¥å¿—é…ç½®** | `configs/logger/wandb.yaml` | âœ… æ­£å¸¸ | WandBé›†æˆå®Œæ•´ |

### 2. é…ç½®ä¼˜åŠ¿

âœ… **Hydraç»„åˆé…ç½®** - æ”¯æŒçµæ´»çš„é…ç½®ç»„åˆ
âœ… **ç¯å¢ƒå˜é‡æ”¯æŒ** - `${oc.env:VAR,default}` å…è®¸åŠ¨æ€è·¯å¾„
âœ… **åˆ†å±‚ç»“æ„** - model/data/trainer/logger æ¸…æ™°åˆ†ç¦»
âœ… **å‘½ä»¤è¡Œè¦†ç›–** - ä»»ä½•å‚æ•°éƒ½å¯ä»¥ä»å‘½ä»¤è¡Œä¿®æ”¹
âœ… **å¤šè¿è¡Œæ”¯æŒ** - sweepæ¨¡å¼æ”¯æŒè¶…å‚æ•°æœç´¢

### 3. ç°æœ‰æ•°æ®é›†ä¿¡æ¯

```
å½“å‰æ•°æ®é›†:
â”œâ”€â”€ master.csv: 673 æ¡ (100%)
â”œâ”€â”€ url_train.csv: 471 æ¡ (70%)
â”œâ”€â”€ url_val.csv: 102 æ¡ (15.2%)
â””â”€â”€ url_test.csv: 104 æ¡ (15.5%)

åˆ—ç»“æ„:
- url_text âœ…
- label âœ…
- timestamp âœ… (æ”¯æŒtemporalåè®®)
- brand âœ… (æ”¯æŒbrand_oodåè®®)
- source âœ…
```

---

## ğŸš€ æœªæ¥æ‰©å±•è§„åˆ’

### é˜¶æ®µ 1: å•æ¨¡å‹è®­ç»ƒ (å½“å‰å·²æ”¯æŒ)

```bash
# URL-onlyæ¨¡å‹ (å½“å‰)
python scripts/train_hydra.py \
  trainer=server \
  logger=wandb \
  run.name=url_only_baseline

# åˆ‡æ¢å¤§æ•°æ®é›† - åªéœ€ä¿®æ”¹ç¯å¢ƒå˜é‡
export DATA_ROOT=/path/to/large_dataset
python scripts/train_hydra.py trainer=server logger=wandb
```

**ç°çŠ¶**: âœ… **å®Œå…¨æ”¯æŒï¼Œæ— éœ€ä¿®æ”¹é…ç½®**

---

### é˜¶æ®µ 2: å¤šæ¨¡å‹ç‹¬ç«‹è®­ç»ƒ

#### 2.1 HTMLç¼–ç å™¨é…ç½® (å¾…åˆ›å»º)

**é…ç½®æ–‡ä»¶**: `configs/model/html_encoder.yaml`

```yaml
# @package _global_
# HTML ç¼–ç å™¨é…ç½®

model:
  _target_: src.models.html_encoder.HTMLEncoder
  pretrained_name: bert-base-uncased
  max_len: 512
  dropout: 0.1
  proj_dim: 256
  num_classes: 2
  freeze_bert: false  # æ˜¯å¦å†»ç»“BERTå‚æ•°
```

**æ•°æ®é…ç½®**: `configs/data/html_only.yaml`

```yaml
# @package _global_
# HTML æ•°æ®é…ç½®

data:
  csv_path: ${oc.env:DATA_ROOT,data/processed}/master.csv
  train_csv: ${oc.env:DATA_ROOT,data/processed}/html_train.csv
  val_csv: ${oc.env:DATA_ROOT,data/processed}/html_val.csv
  test_csv: ${oc.env:DATA_ROOT,data/processed}/html_test.csv
  text_col: html_path  # æŒ‡å‘HTMLæ–‡ä»¶è·¯å¾„
  label_col: label
  num_workers: 4
  batch_format: tuple
```

**è®­ç»ƒå‘½ä»¤**:
```bash
python scripts/train_hydra.py \
  model=html_encoder \
  data=html_only \
  trainer=server \
  logger=wandb \
  run.name=html_only_baseline
```

#### 2.2 å›¾åƒç¼–ç å™¨é…ç½® (å¾…åˆ›å»º)

**é…ç½®æ–‡ä»¶**: `configs/model/image_encoder.yaml`

```yaml
# @package _global_
# å›¾åƒç¼–ç å™¨é…ç½®

model:
  _target_: src.models.image_encoder.ImageEncoder
  backbone: resnet50  # å¯é€‰: resnet50, vit-base
  pretrained: true
  proj_dim: 256
  num_classes: 2
  freeze_backbone: false
  img_size: 224
```

**æ•°æ®é…ç½®**: `configs/data/image_only.yaml`

```yaml
# @package _global_
# å›¾åƒæ•°æ®é…ç½®

data:
  csv_path: ${oc.env:DATA_ROOT,data/processed}/master.csv
  train_csv: ${oc.env:DATA_ROOT,data/processed}/img_train.csv
  val_csv: ${oc.env:DATA_ROOT,data/processed}/img_val.csv
  test_csv: ${oc.env:DATA_ROOT,data/processed}/img_test.csv
  text_col: img_path  # æŒ‡å‘å›¾åƒæ–‡ä»¶è·¯å¾„
  label_col: label
  num_workers: 4
  batch_format: tuple
  # å›¾åƒé¢„å¤„ç†
  img_transforms:
    resize: 224
    normalize: imagenet  # ImageNetå‡å€¼å’Œæ ‡å‡†å·®
```

**è®­ç»ƒå‘½ä»¤**:
```bash
python scripts/train_hydra.py \
  model=image_encoder \
  data=image_only \
  trainer=server \
  logger=wandb \
  run.name=image_only_baseline
```

---

### é˜¶æ®µ 3: å¤šæ¨¡æ€èåˆè®­ç»ƒ

#### 3.1 RCAFèåˆé…ç½® (å¾…åˆ›å»º)

**é…ç½®æ–‡ä»¶**: `configs/model/multimodal_rcaf.yaml`

```yaml
# @package _global_
# RCAF å¤šæ¨¡æ€èåˆé…ç½®

model:
  _target_: src.systems.multimodal_rcaf_module.MultimodalRCAFSystem

  # URLç¼–ç å™¨
  url_encoder:
    _target_: src.models.url_encoder.URLEncoder
    vocab_size: 128
    embedding_dim: 128
    hidden_dim: 128
    num_layers: 2
    bidirectional: true
    dropout: 0.1
    proj_dim: 256
    freeze: false  # æ˜¯å¦å†»ç»“

  # HTMLç¼–ç å™¨
  html_encoder:
    _target_: src.models.html_encoder.HTMLEncoder
    pretrained_name: bert-base-uncased
    max_len: 512
    dropout: 0.1
    proj_dim: 256
    freeze: false

  # å›¾åƒç¼–ç å™¨
  image_encoder:
    _target_: src.models.image_encoder.ImageEncoder
    backbone: resnet50
    pretrained: true
    proj_dim: 256
    freeze: false

  # RCAFèåˆæ¨¡å—
  fusion:
    _target_: src.modules.fusion.rcaf.RCAFFusion
    input_dim: 256  # æ‰€æœ‰ç¼–ç å™¨ç»Ÿä¸€è¾“å‡º256ç»´
    num_modalities: 3
    num_heads: 8
    dropout: 0.1
    use_gate: true  # æ˜¯å¦ä½¿ç”¨é—¨æ§æœºåˆ¶
    reliability_method: consistency  # consistency / uncertainty

  # åˆ†ç±»å¤´
  classifier:
    hidden_dim: 128
    num_classes: 2
    dropout: 0.1

  # æŸå¤±æƒé‡
  loss_weights:
    classification: 1.0
    consistency: 0.1
    reliability: 0.05
```

**æ•°æ®é…ç½®**: `configs/data/multimodal.yaml`

```yaml
# @package _global_
# å¤šæ¨¡æ€æ•°æ®é…ç½®

data:
  csv_path: ${oc.env:DATA_ROOT,data/processed}/master.csv
  train_csv: ${oc.env:DATA_ROOT,data/processed}/train.csv
  val_csv: ${oc.env:DATA_ROOT,data/processed}/val.csv
  test_csv: ${oc.env:DATA_ROOT,data/processed}/test.csv

  # å¤šæ¨¡æ€åˆ—å
  url_col: url_text
  html_col: html_path
  img_col: img_path
  label_col: label

  num_workers: 8
  batch_format: dict  # è¿”å›å­—å…¸æ ¼å¼

  # ç¼ºå¤±æ¨¡æ€å¤„ç†
  handle_missing: mask  # mask / drop / impute

  split_ratios:
    train: 0.7
    val: 0.15
    test: 0.15
```

**è®­ç»ƒå‘½ä»¤**:
```bash
python scripts/train_hydra.py \
  model=multimodal_rcaf \
  data=multimodal \
  trainer=server \
  logger=wandb \
  run.name=rcaf_fusion_v1
```

#### 3.2 å®éªŒé…ç½® (æ¨è)

**é…ç½®æ–‡ä»¶**: `configs/experiment/multimodal_full.yaml`

```yaml
# @package _global_
# å®Œæ•´å¤šæ¨¡æ€å®éªŒé…ç½®

defaults:
  - override /model: multimodal_rcaf
  - override /data: multimodal
  - override /trainer: server
  - override /logger: wandb

run:
  name: multimodal_rcaf_full
  seed: 42

# è¦†ç›–è®­ç»ƒå‚æ•°
train:
  epochs: 30
  batch_size: 32  # å¤šæ¨¡æ€éœ€è¦æ›´å¤šå†…å­˜
  lr: 5e-5  # æ›´å°çš„å­¦ä¹ ç‡
  patience: 10
  gradient_clip_val: 1.0

# WandBæ ‡ç­¾
logger:
  tags: [multimodal, rcaf, fusion]
  notes: "Multi-modal RCAF fusion baseline"
```

**ä½¿ç”¨æ–¹å¼**:
```bash
python scripts/train_hydra.py experiment=multimodal_full
```

---

## ğŸ“‹ é…ç½®è¿ç§»æ¸…å•

### ä»å°æ•°æ®é›†åˆ‡æ¢åˆ°å¤§æ•°æ®é›†

#### æ–¹å¼1: ç¯å¢ƒå˜é‡ (æ¨è)

```bash
# Windows PowerShell
$env:DATA_ROOT = "D:\large_dataset\processed"
python scripts/train_hydra.py trainer=server logger=wandb

# Linux/Mac
export DATA_ROOT=/data/large_dataset/processed
python scripts/train_hydra.py trainer=server logger=wandb
```

#### æ–¹å¼2: å‘½ä»¤è¡Œè¦†ç›–

```bash
python scripts/train_hydra.py \
  data.train_csv=/path/to/large_train.csv \
  data.val_csv=/path/to/large_val.csv \
  data.test_csv=/path/to/large_test.csv \
  trainer=server \
  logger=wandb
```

#### æ–¹å¼3: åˆ›å»ºå¤§æ•°æ®é›†é…ç½®

**é…ç½®æ–‡ä»¶**: `configs/data/url_large.yaml`

```yaml
# @package _global_
# å¤§æ•°æ®é›†é…ç½®

defaults:
  - url_only

data:
  train_csv: /data/large_dataset/url_train.csv
  val_csv: /data/large_dataset/url_val.csv
  test_csv: /data/large_dataset/url_test.csv
  num_workers: 16  # æ›´å¤šworker

train:
  batch_size: 128  # æ›´å¤§æ‰¹æ¬¡

# å¯é€‰: æ•°æ®å¢å¼º
augmentation:
  enabled: true
  prob: 0.3
```

**ä½¿ç”¨**:
```bash
python scripts/train_hydra.py data=url_large trainer=server logger=wandb
```

---

## ğŸ¯ æ¨èçš„é…ç½®ç»“æ„

### ä¸ºæ‚¨çš„å®éªŒåˆ›å»ºé…ç½®

```
configs/
â”œâ”€â”€ config.yaml                 # âœ… å·²æœ‰
â”œâ”€â”€ default.yaml               # âœ… å·²æœ‰
â”‚
â”œâ”€â”€ model/                     # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ url_encoder.yaml       # âœ… å·²æœ‰ (å­—ç¬¦çº§BiLSTM)
â”‚   â”œâ”€â”€ url_encoder_legacy.yaml # âœ… å·²æœ‰ (RoBERTa)
â”‚   â”œâ”€â”€ html_encoder.yaml      # ğŸ”œ å¾…åˆ›å»º
â”‚   â”œâ”€â”€ image_encoder.yaml     # ğŸ”œ å¾…åˆ›å»º
â”‚   â””â”€â”€ multimodal_rcaf.yaml   # ğŸ”œ å¾…åˆ›å»º
â”‚
â”œâ”€â”€ data/                      # æ•°æ®é…ç½®
â”‚   â”œâ”€â”€ url_only.yaml          # âœ… å·²æœ‰
â”‚   â”œâ”€â”€ url_large.yaml         # ğŸ”œ å¾…åˆ›å»º (å¤§æ•°æ®é›†)
â”‚   â”œâ”€â”€ html_only.yaml         # ğŸ”œ å¾…åˆ›å»º
â”‚   â”œâ”€â”€ image_only.yaml        # ğŸ”œ å¾…åˆ›å»º
â”‚   â””â”€â”€ multimodal.yaml        # ğŸ”œ å¾…åˆ›å»º
â”‚
â”œâ”€â”€ trainer/                   # è®­ç»ƒå™¨é…ç½®
â”‚   â”œâ”€â”€ default.yaml           # âœ… å·²æœ‰
â”‚   â”œâ”€â”€ local.yaml             # âœ… å·²æœ‰
â”‚   â”œâ”€â”€ server.yaml            # âœ… å·²æœ‰
â”‚   â””â”€â”€ multi_gpu.yaml         # ğŸ”œ å¯é€‰ (å¤šGPU)
â”‚
â”œâ”€â”€ logger/                    # æ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ csv.yaml               # âœ… å·²æœ‰
â”‚   â”œâ”€â”€ tensorboard.yaml       # âœ… å·²æœ‰
â”‚   â””â”€â”€ wandb.yaml             # âœ… å·²æœ‰
â”‚
â””â”€â”€ experiment/                # å®éªŒé…ç½®
    â”œâ”€â”€ url_baseline.yaml      # âœ… å·²æœ‰
    â”œâ”€â”€ url_large.yaml         # ğŸ”œ å¾…åˆ›å»º
    â”œâ”€â”€ html_baseline.yaml     # ğŸ”œ å¾…åˆ›å»º
    â”œâ”€â”€ image_baseline.yaml    # ğŸ”œ å¾…åˆ›å»º
    â”œâ”€â”€ multimodal_early.yaml  # ğŸ”œ å¾…åˆ›å»º (æ—©æœŸèåˆ)
    â”œâ”€â”€ multimodal_late.yaml   # ğŸ”œ å¾…åˆ›å»º (åæœŸèåˆ)
    â””â”€â”€ multimodal_rcaf.yaml   # ğŸ”œ å¾…åˆ›å»º (RCAFèåˆ)
```

---

## ğŸ’¡ Hydraçš„ä¼˜åŠ¿ - å®Œç¾æ”¯æŒæ‚¨çš„éœ€æ±‚

### 1. âœ… çµæ´»çš„é…ç½®ç»„åˆ

```bash
# å¿«é€Ÿåˆ‡æ¢æ¨¡å‹
python scripts/train_hydra.py model=url_encoder
python scripts/train_hydra.py model=html_encoder
python scripts/train_hydra.py model=multimodal_rcaf

# å¿«é€Ÿåˆ‡æ¢æ•°æ®é›†
python scripts/train_hydra.py data=url_only
python scripts/train_hydra.py data=url_large
python scripts/train_hydra.py data=multimodal

# è‡ªç”±ç»„åˆ
python scripts/train_hydra.py \
  model=multimodal_rcaf \
  data=multimodal \
  trainer=server \
  logger=wandb
```

### 2. âœ… å‘½ä»¤è¡Œè¦†ç›–

```bash
# å¾®è°ƒè¶…å‚æ•°
python scripts/train_hydra.py \
  model=url_encoder \
  train.lr=1e-4 \
  train.batch_size=128 \
  train.epochs=50

# è¦†ç›–ä»»ä½•é…ç½®
python scripts/train_hydra.py \
  model.dropout=0.2 \
  data.num_workers=16 \
  trainer.precision=32
```

### 3. âœ… å®éªŒé…ç½®å¤ç”¨

```bash
# ä½¿ç”¨é¢„å®šä¹‰å®éªŒé…ç½®
python scripts/train_hydra.py experiment=multimodal_full

# åœ¨å®éªŒé…ç½®åŸºç¡€ä¸Šå¾®è°ƒ
python scripts/train_hydra.py \
  experiment=multimodal_full \
  train.lr=1e-4
```

### 4. âœ… è¶…å‚æ•°æœç´¢

```bash
# ç½‘æ ¼æœç´¢
python scripts/train_hydra.py -m \
  model=url_encoder \
  train.lr=1e-3,5e-4,1e-4 \
  model.dropout=0.1,0.2,0.3

# å¯¹æ¯”å¤šä¸ªæ¨¡å‹
python scripts/train_hydra.py -m \
  model=url_encoder,html_encoder,image_encoder \
  trainer=server \
  logger=wandb
```

### 5. âœ… ç¯å¢ƒé€‚é…

```bash
# å¼€å‘ç¯å¢ƒ
python scripts/train_hydra.py \
  trainer=local \
  data.sample_fraction=0.1

# ç”Ÿäº§ç¯å¢ƒ
python scripts/train_hydra.py \
  trainer=server \
  logger=wandb
```

---

## ğŸ”„ è¿ç§»åˆ°å¤§æ•°æ®é›†çš„æ­¥éª¤

### æ­¥éª¤ 1: å‡†å¤‡å¤§æ•°æ®é›†

```bash
# 1. é¢„å¤„ç†å¤§æ•°æ®é›†
python scripts/build_master_and_splits.py \
  --benign /path/to/large_benign \
  --phish /path/to/large_phish \
  --outdir /data/large_dataset/processed

# 2. éªŒè¯æ•°æ®
python scripts/validate_data_schema.py \
  --data_root /data/large_dataset/processed

# 3. æ£€æŸ¥ç»Ÿè®¡
python -c "
import pandas as pd
for split in ['train', 'val', 'test']:
    df = pd.read_csv(f'/data/large_dataset/processed/{split}.csv')
    print(f'{split}: {len(df)} samples')
"
```

### æ­¥éª¤ 2: é…ç½®ç¯å¢ƒå˜é‡

```bash
# Windows PowerShell
$env:DATA_ROOT = "D:\large_dataset\processed"
$env:WANDB_PROJECT = "uaam-phish-large"
$env:WANDB_ENTITY = "your-team"

# Linux/Mac
export DATA_ROOT=/data/large_dataset/processed
export WANDB_PROJECT=uaam-phish-large
export WANDB_ENTITY=your-team
```

### æ­¥éª¤ 3: è¿è¡ŒåŸºçº¿å®éªŒ

```bash
# URL-onlyåŸºçº¿
python scripts/train_hydra.py \
  trainer=server \
  logger=wandb \
  run.name=url_large_baseline_v1

# ä¿å­˜æœ€ä½³é…ç½®
python scripts/train_hydra.py \
  trainer=server \
  logger=wandb \
  run.name=url_large_baseline_v2 \
  train.lr=5e-4 \
  train.batch_size=128
```

### æ­¥éª¤ 4: å¯¹æ¯”å®éªŒ

```bash
# è¿è¡Œå®Œæˆåå¯¹æ¯”
python scripts/compare_experiments.py \
  --exp_names url_large_baseline_v1 url_large_baseline_v2 \
  --metric auroc
```

---

## ğŸ“ æœ€ä½³å®è·µå»ºè®®

### 1. ä½¿ç”¨å®éªŒé…ç½®æ–‡ä»¶

**å¥½å¤„**:
- âœ… é…ç½®å¯å¤ç°
- âœ… æ˜“äºåˆ†äº«
- âœ… ç‰ˆæœ¬æ§åˆ¶å‹å¥½

**ç¤ºä¾‹**:
```yaml
# configs/experiment/my_large_experiment.yaml
defaults:
  - override /model: url_encoder
  - override /data: url_large
  - override /trainer: server
  - override /logger: wandb

run:
  name: large_url_experiment_v1
  seed: 42

train:
  epochs: 50
  batch_size: 128
  lr: 5e-4
```

### 2. ä½¿ç”¨WandBæ ‡ç­¾ç»„ç»‡å®éªŒ

```bash
python scripts/train_hydra.py \
  trainer=server \
  logger=wandb \
  logger.tags=[large-dataset,url-only,baseline]
```

### 3. æ¸è¿›å¼è®­ç»ƒ

```bash
# 1. å°æ•°æ®é›†éªŒè¯
python scripts/train_hydra.py \
  trainer=local \
  data.sample_fraction=0.1

# 2. ä¸­ç­‰æ•°æ®é›†
python scripts/train_hydra.py \
  trainer=server \
  data.sample_fraction=0.3

# 3. å®Œæ•´æ•°æ®é›†
python scripts/train_hydra.py \
  trainer=server \
  logger=wandb
```

---

## âœ… é…ç½®å¥åº·æ€»ç»“

| é¡¹ç›® | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| **å½“å‰é…ç½®** | âœ… å¥åº· | æ‰€æœ‰é…ç½®æ­£ç¡®ï¼Œæ— éœ€ä¿®æ”¹ |
| **Hydraæ”¯æŒ** | âœ… å®Œæ•´ | æ”¯æŒæ‰€æœ‰æœªæ¥åœºæ™¯ |
| **å¯æ‰©å±•æ€§** | âœ… ä¼˜ç§€ | æ˜“äºæ·»åŠ æ–°æ¨¡å‹/æ•°æ®é…ç½® |
| **å¤§æ•°æ®é›†æ”¯æŒ** | âœ… å°±ç»ª | åªéœ€è®¾ç½®ç¯å¢ƒå˜é‡ |
| **å¤šæ¨¡å‹æ”¯æŒ** | âœ… å°±ç»ª | æ·»åŠ é…ç½®æ–‡ä»¶å³å¯ |
| **èåˆæ”¯æŒ** | âœ… å°±ç»ª | Hydraå®Œç¾æ”¯æŒå¤æ‚é…ç½® |

---

## ğŸš€ ç«‹å³å¯ç”¨çš„å‘½ä»¤

### å½“å‰ï¼ˆå°æ•°æ®é›†ï¼‰

```bash
# å¿«é€Ÿæµ‹è¯•
python scripts/train_hydra.py trainer=local

# GPUè®­ç»ƒ
python scripts/train_hydra.py trainer=server logger=wandb
```

### åˆ‡æ¢å¤§æ•°æ®é›†

```bash
# æ–¹å¼1: ç¯å¢ƒå˜é‡
export DATA_ROOT=/path/to/large_dataset
python scripts/train_hydra.py trainer=server logger=wandb

# æ–¹å¼2: å‘½ä»¤è¡Œ
python scripts/train_hydra.py \
  data.train_csv=/path/to/large_train.csv \
  data.val_csv=/path/to/large_val.csv \
  data.test_csv=/path/to/large_test.csv \
  trainer=server \
  logger=wandb
```

### æœªæ¥å¤šæ¨¡å‹ï¼ˆéœ€å…ˆå®ç°æ¨¡å‹ä»£ç ï¼‰

```bash
# HTMLæ¨¡å‹
python scripts/train_hydra.py \
  model=html_encoder \
  data=html_only \
  trainer=server \
  logger=wandb

# å›¾åƒæ¨¡å‹
python scripts/train_hydra.py \
  model=image_encoder \
  data=image_only \
  trainer=server \
  logger=wandb

# RCAFèåˆ
python scripts/train_hydra.py \
  model=multimodal_rcaf \
  data=multimodal \
  trainer=server \
  logger=wandb
```

---

## ğŸ“ ç»“è®º

### âœ… æ‚¨çš„é…ç½®å·²ç»å®Œå…¨æ»¡è¶³æœªæ¥éœ€æ±‚ï¼

**å½“å‰çŠ¶æ€**:
- âœ… Hydraé…ç½®ç»“æ„å®Œå–„
- âœ… æ”¯æŒçµæ´»çš„é…ç½®ç»„åˆ
- âœ… æ”¯æŒå¤§æ•°æ®é›†ï¼ˆç¯å¢ƒå˜é‡ï¼‰
- âœ… æ”¯æŒè¶…å‚æ•°æœç´¢
- âœ… æ”¯æŒå¤šGPUè®­ç»ƒ

**ä¸‹ä¸€æ­¥**:
1. **ç°åœ¨**: åˆ‡æ¢åˆ°å¤§æ•°æ®é›†ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰é…ç½®è®­ç»ƒ
2. **ä¹‹å**: å®ç°HTML/Imageç¼–ç å™¨ï¼Œæ·»åŠ å¯¹åº”é…ç½®æ–‡ä»¶
3. **æœ€å**: å®ç°RCAFèåˆï¼Œæ·»åŠ èåˆé…ç½®æ–‡ä»¶

**Hydraçš„ä¼˜åŠ¿ç¡®ä¿æ‚¨å¯ä»¥è½»æ¾å›å¤´è®­ç»ƒä»»ä½•é…ç½®ï¼**

---

**é…ç½®æ£€æŸ¥å®Œæˆï¼æ‚¨å¯ä»¥æ”¾å¿ƒåœ°è¿›è¡Œå¤§æ•°æ®é›†è®­ç»ƒäº†ï¼** ğŸ‰
