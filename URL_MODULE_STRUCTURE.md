# URL æ¨¡å—é¡¹ç›®ç»“æ„ï¼ˆå®Œæ•´é€»è¾‘æµç¨‹ï¼‰

> **æ›´æ–°æ—¶é—´**: 2025-10-22
> **çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

---

## ğŸ“‹ ç›®å½•

1. [æ•°æ®æµç¨‹](#1-æ•°æ®æµç¨‹)
2. [é…ç½®ç³»ç»Ÿ](#2-é…ç½®ç³»ç»Ÿ)
3. [æ ¸å¿ƒæ¨¡å—](#3-æ ¸å¿ƒæ¨¡å—)
4. [è®­ç»ƒç³»ç»Ÿ](#4-è®­ç»ƒç³»ç»Ÿ)
5. [æ¨ç†é¢„æµ‹](#5-æ¨ç†é¢„æµ‹)
6. [å·¥å…·éªŒè¯](#6-å·¥å…·éªŒè¯)
7. [å®éªŒäº§å‡º](#7-å®éªŒäº§å‡º)
8. [æ–‡æ¡£ç³»ç»Ÿ](#8-æ–‡æ¡£ç³»ç»Ÿ)

---

## 1. æ•°æ®æµç¨‹

### 1.1 åŸå§‹æ•°æ®æº

```
data/raw/
â”œâ”€â”€ dataset/              â† åˆæ³•ç½‘ç«™æ•°æ®ï¼ˆbenignï¼‰
â”‚   â””â”€â”€ *.csv
â””â”€â”€ fish_dataset/         â† é’“é±¼ç½‘ç«™æ•°æ®ï¼ˆphishingï¼‰
    â””â”€â”€ *.csv
```

**è¯´æ˜**:
- ä¸¤ä¸ªæ•°æ®æºåˆ†åˆ«å­˜æ”¾åˆæ³•å’Œé’“é±¼ç½‘ç«™çš„åŸå§‹æ•°æ®
- å¿…é¡»åŒ…å«: `url_text`, `label`, `timestamp`(å¯é€‰), `brand`(å¯é€‰), `source`(å¯é€‰)

---

### 1.2 æ•°æ®å¤„ç†è„šæœ¬

#### ç”Ÿæˆä¸»æ•°æ®é›†
```bash
# è„šæœ¬ä½ç½®
scripts/build_master_and_splits.py
scripts/create_master_csv.py        # ç®€åŒ–ç‰ˆï¼Œåªç”Ÿæˆ master.csv

# ç”¨æ³•
python scripts/create_master_csv.py

# äº§å‡º
data/processed/master.csv           # åˆå¹¶åçš„ä¸»æ•°æ®é›†
```

**master.csv å¿…éœ€åˆ—**:
- `url_text`: URL æ–‡æœ¬ï¼ˆå¿…éœ€ï¼‰
- `label`: æ ‡ç­¾ 0=åˆæ³•, 1=é’“é±¼ï¼ˆå¿…éœ€ï¼‰
- `timestamp`: æ—¶é—´æˆ³ï¼ˆtemporalåè®®éœ€è¦ï¼‰
- `brand`: å“ç‰Œåç§°ï¼ˆbrand_oodåè®®éœ€è¦ï¼‰
- `source`: æ•°æ®æ¥æºï¼ˆå¯é€‰ï¼‰

---

### 1.3 æ•°æ®åˆ†å‰²ï¼ˆä¸‰åè®®ï¼‰

#### åˆ†å‰²ç­–ç•¥å®ç°
```python
# ä½ç½®: src/utils/splits.py

def build_splits(df, cfg, protocol) -> (train_df, val_df, test_df, metadata):
    """
    ä¸‰ç§åè®®:
    - random: éšæœºåˆ†å‰² (é»˜è®¤ 70/15/15)
    - temporal: æ—¶é—´åºåˆ—åˆ†å‰² (æŒ‰timestampæ’åº)
    - brand_ood: å“ç‰ŒåŸŸå¤–åˆ†å‰² (train/testå“ç‰Œä¸é‡å )
    """
```

#### è‡ªåŠ¨åˆ†å‰²æœºåˆ¶
```python
# ä½ç½®: src/datamodules/url_datamodule.py

class UrlDataModule:
    def setup(self, stage="fit"):
        if self.cfg.get("use_build_splits", False):
            # è‡ªåŠ¨è°ƒç”¨ build_splits ç”Ÿæˆåˆ†å‰²
            train_df, val_df, test_df, metadata = build_splits(...)
            # ä¿å­˜åˆ° CSV
            train_df.to_csv(data/processed/url_train.csv)
            val_df.to_csv(data/processed/url_val.csv)
            test_df.to_csv(data/processed/url_test.csv)
            # ä¿å­˜å…ƒæ•°æ®ä¾›åç»­ä½¿ç”¨
            self.split_metadata = metadata
```

#### åˆ†å‰²äº§å‡º
```
data/processed/
â”œâ”€â”€ master.csv            # ä¸»æ•°æ®é›†ï¼ˆè¾“å…¥ï¼‰
â”œâ”€â”€ url_train.csv         # è®­ç»ƒé›†ï¼ˆè¾“å‡ºï¼‰
â”œâ”€â”€ url_val.csv           # éªŒè¯é›†ï¼ˆè¾“å‡ºï¼‰
â””â”€â”€ url_test.csv          # æµ‹è¯•é›†ï¼ˆè¾“å‡ºï¼‰
```

---

### 1.4 æ•°æ®é›†ç±»ï¼ˆå­—ç¬¦çº§ç¼–ç ï¼‰

```python
# ä½ç½®: src/data/url_dataset.py

class UrlDataset(Dataset):
    """
    å­—ç¬¦çº§ URL æ•°æ®é›†
    - è¾“å…¥: CSV æ–‡ä»¶ (url_text, label)
    - ç¼–ç : å­—ç¬¦ â†’ ASCIIç  (0-127)
    - è¾“å‡º: (input_ids: Tensor[L], label: int)
    """

def encode_url(text, max_len, vocab_size, pad_id):
    """
    å­—ç¬¦çº§ç¼–ç å‡½æ•°:
    1. æ¯ä¸ªå­—ç¬¦ â†’ ord(char)
    2. è¶…å‡ºvocab_size â†’ vocab_size-1
    3. å¡«å……åˆ° max_len
    """
```

**é»˜è®¤å‚æ•°**:
- `max_len`: 256 å­—ç¬¦
- `vocab_size`: 128 (ASCIIæ ‡å‡†)
- `pad_id`: 0

---

## 2. é…ç½®ç³»ç»Ÿ

### 2.1 é…ç½®ç»“æ„ï¼ˆHydraï¼‰

```
configs/
â”œâ”€â”€ config.yaml           # ä¸»é…ç½®ï¼ˆç»„åˆæ‰€æœ‰éƒ¨åˆ†ï¼‰
â”œâ”€â”€ default.yaml          # é»˜è®¤åŸºç¡€é…ç½®
â”œâ”€â”€ base.yaml             # åŸºç¡€è®¾ç½®
â”œâ”€â”€ hparams.yaml          # è¶…å‚æ•°
â”œâ”€â”€ encoders.yaml         # ç¼–ç å™¨é…ç½®
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ url_only.yaml     # URLæ•°æ®é…ç½® â­
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ url_encoder.yaml  # URLç¼–ç å™¨æ¨¡å‹é…ç½® â­
â”‚
â”œâ”€â”€ trainer/
â”‚   â”œâ”€â”€ local.yaml        # æœ¬åœ°å¿«é€Ÿæµ‹è¯• (10%æ•°æ®, 5 epochs)
â”‚   â”œâ”€â”€ server.yaml       # æœåŠ¡å™¨å®Œæ•´è®­ç»ƒ
â”‚   â””â”€â”€ default.yaml      # é»˜è®¤è®­ç»ƒå™¨
â”‚
â”œâ”€â”€ profiles/
â”‚   â”œâ”€â”€ local.yaml        # æœ¬åœ°ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ server.yaml       # æœåŠ¡å™¨ç¯å¢ƒé…ç½®
â”‚
â”œâ”€â”€ experiment/
â”‚   â””â”€â”€ url_baseline.yaml # URLåŸºçº¿å®éªŒé…ç½® â­
â”‚
â””â”€â”€ logger/
    â”œâ”€â”€ csv.yaml          # CSVæ—¥å¿—
    â”œâ”€â”€ tensorboard.yaml  # TensorBoard
    â””â”€â”€ wandb.yaml        # Weights & Biases
```

---

### 2.2 æ ¸å¿ƒé…ç½®æ–‡ä»¶

#### A. URL æ•°æ®é…ç½®
```yaml
# configs/data/url_only.yaml
data:
  csv_path: data/processed/master.csv      # ä¸»æ•°æ®é›†
  train_csv: data/processed/url_train.csv  # è®­ç»ƒé›†
  val_csv: data/processed/url_val.csv      # éªŒè¯é›†
  test_csv: data/processed/url_test.csv    # æµ‹è¯•é›†

  text_col: url_text                       # URLæ–‡æœ¬åˆ—å
  label_col: label                         # æ ‡ç­¾åˆ—å
  timestamp_col: timestamp                 # æ—¶é—´æˆ³åˆ—å
  brand_col: brand                         # å“ç‰Œåˆ—å
  source_col: source                       # æ¥æºåˆ—å

  num_workers: 4                           # DataLoaderå·¥ä½œè¿›ç¨‹æ•°
  batch_format: tuple                      # æ‰¹æ¬¡æ ¼å¼: (input_ids, labels)

  split_ratios:
    train: 0.7                             # è®­ç»ƒé›†æ¯”ä¾‹
    val: 0.15                              # éªŒè¯é›†æ¯”ä¾‹
    test: 0.15                             # æµ‹è¯•é›†æ¯”ä¾‹
```

#### B. URL ç¼–ç å™¨é…ç½®
```yaml
# configs/model/url_encoder.yaml
model:
  vocab_size: 128           # ASCIIå­—ç¬¦é›†å¤§å°
  embedding_dim: 128        # å­—ç¬¦åµŒå…¥ç»´åº¦
  hidden_dim: 128           # LSTMéšè—å±‚ç»´åº¦
  num_layers: 2             # LSTMå±‚æ•° (å›ºå®š)
  bidirectional: true       # åŒå‘LSTM (å›ºå®š)
  dropout: 0.1              # Dropoutç‡
  pad_id: 0                 # å¡«å……ç¬¦å·ID
  proj_dim: 256             # æŠ•å½±å±‚ç»´åº¦ (å›ºå®š)
  max_len: 256              # URLæœ€å¤§é•¿åº¦
  num_classes: 2            # åˆ†ç±»æ•°ï¼ˆäºŒåˆ†ç±»ï¼‰
```

**ğŸ”’ æ¶æ„é”å®š**:
- 2å±‚åŒå‘LSTM
- å­—ç¬¦çº§ç¼–ç 
- 256ç»´è¾“å‡º
- ä»£ç ä¸­æœ‰æ–­è¨€ä¿æŠ¤ï¼Œä¸å¯ä¿®æ”¹

---

## 3. æ ¸å¿ƒæ¨¡å—

### 3.1 URL ç¼–ç å™¨ï¼ˆBiLSTMï¼‰

```python
# ä½ç½®: src/models/url_encoder.py

class URLEncoder(nn.Module):
    """
    å­—ç¬¦çº§åŒå‘LSTMç¼–ç å™¨

    æ¶æ„ï¼ˆå›ºå®šï¼‰:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Input: URLå­—ç¬¦åºåˆ—     â”‚
    â”‚  [char_1, ..., char_n]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Embedding (128-dim)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Dropout (0.1)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  BiLSTM (2 layers)      â”‚
    â”‚  Hidden: 128            â”‚
    â”‚  Output: 256 (2Ã—128)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Projection (256-dim)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Output: z_url âˆˆ R^256  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """

    def forward(self, input_ids):
        # 1. å­—ç¬¦åµŒå…¥
        embeddings = self.embedding(input_ids)

        # 2. BiLSTMç¼–ç 
        _, (hidden, _) = self.lstm(embeddings)
        forward_h = hidden[-2]   # å‰å‘æœ€åå±‚
        backward_h = hidden[-1]  # åå‘æœ€åå±‚
        features = torch.cat([forward_h, backward_h], dim=1)

        # 3. æŠ•å½±åˆ°256ç»´
        return self.project(features)
```

**å‚æ•°é‡**:
- Embedding: 128 Ã— 128 = 16,384
- LSTM: ~200K
- Projection: 256 Ã— 256 = 65,536
- **æ€»è®¡**: ~282K å‚æ•°

---

### 3.2 URL-Only ç³»ç»Ÿæ¨¡å—

```python
# ä½ç½®: src/systems/url_only_module.py

class UrlOnlyModule(pl.LightningModule):
    """
    å®Œæ•´çš„è®­ç»ƒ/è¯„ä¼°ç³»ç»Ÿ

    ç»„ä»¶:
    1. URLEncoder (ç¼–ç å™¨)
    2. Linear Classifier (åˆ†ç±»å™¨)
    3. Metrics (æŒ‡æ ‡è®¡ç®—)
    4. Loss (æŸå¤±å‡½æ•°)
    """

    def __init__(self, cfg):
        # ç¼–ç å™¨
        self.encoder = URLEncoder(...)

        # åˆ†ç±»å™¨ï¼ˆçº¿æ€§å±‚ï¼‰
        self.classifier = nn.Linear(proj_dim, num_classes)

        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()

        # æ­¥çº§æŒ‡æ ‡ (æ¯ä¸ªbatchè®¡ç®—)
        self.train_metrics = {
            "accuracy": Accuracy(),
            "auroc": AUROC(pos_label=1),
            "f1": F1Score(average="macro")
        }

        # è½®æ¬¡çº§æŒ‡æ ‡ (æ•´ä¸ªepochè®¡ç®—)
        # NLL: è´Ÿå¯¹æ•°ä¼¼ç„¶
        # ECE: æœŸæœ›æ ¡å‡†è¯¯å·®ï¼ˆè‡ªé€‚åº”binsï¼‰

    def forward(self, input_ids):
        """ç¼–ç : URL â†’ 256ç»´å‘é‡"""
        return self.encoder(input_ids)

    def predict_logits(self, input_ids):
        """é¢„æµ‹: URL â†’ logits (2ç»´)"""
        z = self.forward(input_ids)
        return self.classifier(z)

    def training_step(self, batch, batch_idx):
        """è®­ç»ƒæ­¥éª¤"""
        input_ids, labels = batch
        logits = self.predict_logits(input_ids)
        loss = self.criterion(logits, labels)
        return loss

    def validation_step(self, batch, batch_idx):
        """éªŒè¯æ­¥éª¤ï¼ˆè®¡ç®—æ­¥çº§+è½®æ¬¡çº§æŒ‡æ ‡ï¼‰"""
        # ... åŒä¸Šï¼Œå¹¶æ”¶é›†è¾“å‡ºä¾› on_validation_epoch_end ä½¿ç”¨

    def test_step(self, batch, batch_idx):
        """æµ‹è¯•æ­¥éª¤ï¼ˆæ”¶é›†é¢„æµ‹ç”¨äºå¯è§†åŒ–ï¼‰"""
        # ... åŒä¸Š

    def on_validation_epoch_end(self):
        """éªŒè¯è½®æ¬¡ç»“æŸï¼ˆè®¡ç®—NLLå’ŒECEï¼‰"""
        all_logits = torch.cat([...])
        all_labels = torch.cat([...])
        all_probs = torch.softmax(all_logits, dim=1)

        # è®¡ç®— NLL
        nll = compute_nll(all_logits, all_labels)

        # è®¡ç®— ECEï¼ˆè‡ªé€‚åº”binsï¼‰
        ece, bins_used = compute_ece(y_true, y_prob, n_bins=None)

        self.log("val_nll", nll)
        self.log("val_ece", ece)

    def configure_optimizers(self):
        """ä¼˜åŒ–å™¨: AdamW"""
        return torch.optim.AdamW(self.parameters(), lr=cfg.train.lr)
```

**æŒ‡æ ‡ä½“ç³»**:

| æŒ‡æ ‡ç±»å‹ | æŒ‡æ ‡åç§° | è®¡ç®—æ—¶æœº | è¯´æ˜ |
|---------|---------|---------|------|
| æ­¥çº§ | Accuracy | æ¯ä¸ªbatch | å‡†ç¡®ç‡ |
| æ­¥çº§ | AUROC | æ¯ä¸ªbatch | ROCæ›²çº¿ä¸‹é¢ç§¯ï¼ˆpos_label=1ï¼‰ |
| æ­¥çº§ | F1-macro | æ¯ä¸ªbatch | å®å¹³å‡F1åˆ†æ•° |
| è½®æ¬¡çº§ | NLL | æ¯ä¸ªepoch | è´Ÿå¯¹æ•°ä¼¼ç„¶ |
| è½®æ¬¡çº§ | ECE | æ¯ä¸ªepoch | æœŸæœ›æ ¡å‡†è¯¯å·®ï¼ˆè‡ªé€‚åº”bins: 3-15ï¼‰ |

---

### 3.3 æ•°æ®æ¨¡å—ï¼ˆDataModuleï¼‰

```python
# ä½ç½®: src/datamodules/url_datamodule.py

class UrlDataModule(pl.LightningDataModule):
    """
    Lightning æ•°æ®æ¨¡å—

    åŠŸèƒ½:
    1. æ•°æ®åŠ è½½: ä»CSVè¯»å–
    2. è‡ªåŠ¨åˆ†å‰²: use_build_splits=trueæ—¶è°ƒç”¨build_splits
    3. DataLoader: æä¾›train/val/teståŠ è½½å™¨
    """

    def __init__(self, cfg):
        self.cfg = cfg
        self.split_metadata = {}  # åˆ†å‰²å…ƒæ•°æ®ï¼ˆä¾›callbacksä½¿ç”¨ï¼‰

    def setup(self, stage):
        # å¦‚æœå¯ç”¨ use_build_splitsï¼Œè‡ªåŠ¨ç”Ÿæˆåˆ†å‰²
        if stage == "fit" and cfg.get("use_build_splits", False):
            train_df, val_df, test_df, metadata = build_splits(...)
            # ä¿å­˜åˆ†å‰²
            train_df.to_csv(train_csv)
            val_df.to_csv(val_csv)
            test_df.to_csv(test_csv)
            # ä¿å­˜å…ƒæ•°æ®
            self.split_metadata = metadata

        # åˆ›å»ºæ•°æ®é›†
        self.train_dataset = UrlDataset(train_csv, ...)
        self.val_dataset = UrlDataset(val_csv, ...)
        self.test_dataset = UrlDataset(test_csv, ...)

    def train_dataloader(self):
        return DataLoader(self.train_dataset, batch_size=..., shuffle=True)

    def val_dataloader(self):
        return DataLoader(self.val_dataset, batch_size=..., shuffle=False)

    def test_dataloader(self):
        return DataLoader(self.test_dataset, batch_size=..., shuffle=False)
```

---

## 4. è®­ç»ƒç³»ç»Ÿ

### 4.1 è®­ç»ƒè„šæœ¬ï¼ˆHydraç‰ˆï¼‰

```python
# ä½ç½®: scripts/train_hydra.py

@hydra.main(config_path="../configs", config_name="config")
def train(cfg):
    """
    Hydraè®­ç»ƒä¸»å‡½æ•°

    æµç¨‹:
    1. è®¾ç½®éšæœºç§å­
    2. åˆå§‹åŒ–æ•°æ®æ¨¡å—å’Œæ¨¡å‹
    3. é…ç½®callbacks
    4. é…ç½®trainer
    5. è®­ç»ƒ: trainer.fit(model, datamodule)
    6. æµ‹è¯•: trainer.test(model, datamodule)
    7. ç”Ÿæˆå¯è§†åŒ–å’Œäº§ç‰©
    """

    # 1. åˆå§‹åŒ–
    pl.seed_everything(cfg.run.seed)
    dm = UrlDataModule(cfg)
    model = UrlOnlySystem(cfg)

    # 2. é…ç½®callbacks
    callbacks = [
        EarlyStopping(monitor="val_loss", patience=3),
        ModelCheckpoint(monitor="val_loss", mode="min", save_top_k=1),
        ExperimentResultsCallback(exp_tracker),      # ä¿å­˜å®éªŒé…ç½®
        TestPredictionCollector(),                   # æ”¶é›†æµ‹è¯•é¢„æµ‹
        ProtocolArtifactsCallback(protocol, ...),    # ç”Ÿæˆåè®®äº§ç‰©
        DocumentationCallback(...),                   # è‡ªåŠ¨æ–‡æ¡£è¿½åŠ ï¼ˆå¯é€‰ï¼‰
    ]

    # 3. é…ç½®trainer
    trainer = pl.Trainer(
        max_epochs=cfg.train.epochs,
        accelerator=cfg.hardware.accelerator,
        devices=cfg.hardware.devices,
        callbacks=callbacks,
        logger=logger,
    )

    # 4. è®­ç»ƒ
    trainer.fit(model, dm)

    # 5. æ›´æ–° split_metadataï¼ˆä» dm ä¼ é€’ç»™ callbackï¼‰
    protocol_callback.split_metadata = dm.split_metadata

    # 6. æµ‹è¯•
    trainer.test(model, dm, ckpt_path="best")

    # 7. ç”Ÿæˆå¯è§†åŒ–
    ResultVisualizer.create_all_plots(
        metrics_csv=...,
        y_true=...,
        y_prob=...,
        output_dir=exp_tracker.results_dir,
    )
```

---

### 4.2 è¿è¡Œå‘½ä»¤

#### å•åè®®è¿è¡Œ
```bash
# Random åè®®
python scripts/train_hydra.py protocol=random use_build_splits=true

# Temporal åè®®
python scripts/train_hydra.py protocol=temporal use_build_splits=true

# Brand-OOD åè®®
python scripts/train_hydra.py protocol=brand_ood use_build_splits=true
```

#### ä¸€é”®è¿è¡Œï¼ˆä¸‰åè®®ï¼‰
```bash
# Linux/Mac
bash scripts/run_all_protocols.sh

# Windows PowerShell
.\scripts\run_all_protocols.ps1
```

#### è‡ªå®šä¹‰å‚æ•°
```bash
# ä½¿ç”¨æœ¬åœ°é…ç½®ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python scripts/train_hydra.py protocol=random use_build_splits=true +profiles/local

# è‡ªå®šä¹‰batch sizeå’Œepochs
python scripts/train_hydra.py protocol=random use_build_splits=true train.bs=128 train.epochs=50

# ä½¿ç”¨WandBæ—¥å¿—
python scripts/train_hydra.py protocol=random use_build_splits=true logger=wandb
```

#### è¶…å‚æ•°æœç´¢ï¼ˆå¤šè¿è¡Œï¼‰
```bash
# å­¦ä¹ ç‡å’Œdropoutç½‘æ ¼æœç´¢
python scripts/train_hydra.py -m \
  protocol=random \
  use_build_splits=true \
  train.lr=1e-5,2e-5,5e-5 \
  model.dropout=0.1,0.2,0.3
```

---

### 4.3 Callbacksï¼ˆå›è°ƒç³»ç»Ÿï¼‰

```python
# 1. ExperimentResultsCallback
# ä½ç½®: src/utils/callbacks.py
# åŠŸèƒ½: ä¿å­˜å®éªŒé…ç½®å’Œå…ƒæ•°æ®åˆ° results/ ç›®å½•

# 2. TestPredictionCollector
# ä½ç½®: src/utils/callbacks.py
# åŠŸèƒ½: æ”¶é›†æµ‹è¯•é›†é¢„æµ‹ï¼ˆy_true, y_probï¼‰ä¾›å¯è§†åŒ–ä½¿ç”¨

# 3. ProtocolArtifactsCallback
# ä½ç½®: src/utils/protocol_artifacts.py
# åŠŸèƒ½: ç”Ÿæˆåè®®å››ä»¶å¥—äº§ç‰©
#   - roc_{protocol}.png
#   - calib_{protocol}.png
#   - splits_{protocol}.csv
#   - metrics_{protocol}.json

# 4. DocumentationCallback
# ä½ç½®: src/utils/doc_callback.py
# åŠŸèƒ½: è‡ªåŠ¨è¿½åŠ å®éªŒè®°å½•åˆ°é¡¹ç›®æ–‡æ¡£
```

---

## 5. æ¨ç†é¢„æµ‹

### 5.1 é¢„æµ‹è„šæœ¬

```python
# ä½ç½®: scripts/predict.py

# å•URLé¢„æµ‹
python scripts/predict.py \
  --checkpoint experiments/url_only/checkpoints/url-only-best.ckpt \
  --url "https://example.com/login"

# æ‰¹é‡é¢„æµ‹
python scripts/predict.py \
  --checkpoint experiments/url_only/checkpoints/url-only-best.ckpt \
  --test data/processed/url_test.csv \
  --out predictions.csv
```

### 5.2 é¢„æµ‹æµç¨‹

```python
# 1. åŠ è½½æ¨¡å‹
model = UrlOnlyModule.load_from_checkpoint(checkpoint_path)
model.eval()

# 2. ç¼–ç URL
input_ids = encode_url(url, max_len=256, vocab_size=128, pad_id=0)
input_tensor = torch.tensor([input_ids])

# 3. é¢„æµ‹
with torch.no_grad():
    logits = model.predict_logits(input_tensor)
    probs = torch.softmax(logits, dim=1)
    pred_class = logits.argmax(dim=1).item()
    confidence = probs[0, pred_class].item()

# 4. è¾“å‡º
print(f"é¢„æµ‹ç±»åˆ«: {pred_class} (0=åˆæ³•, 1=é’“é±¼)")
print(f"ç½®ä¿¡åº¦: {confidence:.4f}")
```

---

## 6. å·¥å…·éªŒè¯

### 6.1 äº§ç‰©éªŒè¯å·¥å…·

```python
# ä½ç½®: tools/check_artifacts_url_only.py

# è‡ªåŠ¨éªŒè¯æœ€æ–°å®éªŒ
python tools/check_artifacts_url_only.py

# éªŒè¯ç‰¹å®šå®éªŒ
python tools/check_artifacts_url_only.py experiments/url_random_20251022_120000
```

**éªŒè¯é¡¹**:
1. âœ… å››ä»¶å¥—æ–‡ä»¶å­˜åœ¨æ€§
2. âœ… `splits_{protocol}.csv` 13åˆ—å®Œæ•´æ€§
3. âœ… `metrics_{protocol}.json` schemaå®Œæ•´æ€§
4. âœ… ECE binsèŒƒå›´åˆç†æ€§ [3, 15]
5. âœ… åè®®ç‰¹å®šéªŒè¯
   - brand_ood: `brand_intersection_ok == true`
   - temporal: `tie_policy == "left-closed"`

---

### 6.2 æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥

```bash
# æ£€æŸ¥æ•°æ®é‡å 
python check_overlap.py

# éªŒè¯æ•°æ®schema
python scripts/validate_data_schema.py
```

---

## 7. å®éªŒäº§å‡º

### 7.1 å®éªŒç›®å½•ç»“æ„

```
experiments/
â””â”€â”€ url_{protocol}_{timestamp}/          # å•æ¬¡å®éªŒç›®å½•
    â”œâ”€â”€ config/                          # é…ç½®å¤‡ä»½
    â”‚   â””â”€â”€ config.yaml
    â”‚
    â”œâ”€â”€ checkpoints/                     # æ¨¡å‹æ£€æŸ¥ç‚¹
    â”‚   â””â”€â”€ best-epoch=X-val_loss=Y.ckpt
    â”‚
    â”œâ”€â”€ results/                         # å®éªŒç»“æœ â­
    â”‚   â”œâ”€â”€ roc_{protocol}.png           # ROCæ›²çº¿å›¾
    â”‚   â”œâ”€â”€ calib_{protocol}.png         # æ ¡å‡†æ›²çº¿å›¾ï¼ˆå«ECEæ ‡æ³¨ï¼‰
    â”‚   â”œâ”€â”€ splits_{protocol}.csv        # æ•°æ®åˆ†å‰²ç»Ÿè®¡è¡¨ï¼ˆ13åˆ—ï¼‰
    â”‚   â”œâ”€â”€ metrics_{protocol}.json      # æŒ‡æ ‡JSONï¼ˆ9ä¸ªkeyï¼‰
    â”‚   â””â”€â”€ implementation_report.md     # å®ç°æŠ¥å‘Š
    â”‚
    â””â”€â”€ lightning_logs/                  # PyTorch Lightningæ—¥å¿—
        â””â”€â”€ version_0/
            â””â”€â”€ metrics.csv              # è®­ç»ƒè¿‡ç¨‹æŒ‡æ ‡
```

---

### 7.2 å››ä»¶å¥—è¯¦è§£

#### A. ROCæ›²çº¿å›¾ (`roc_{protocol}.png`)

```python
# ç”Ÿæˆ: src/utils/visualizer.py :: save_roc_curve()

å†…å®¹:
- Xè½´: False Positive Rate (FPR)
- Yè½´: True Positive Rate (TPR)
- æ›²çº¿: ROC curve
- æ ‡æ³¨: AUC = 0.xxxx
- åŸºçº¿: å¯¹è§’çº¿ï¼ˆéšæœºåˆ†ç±»å™¨ï¼‰
```

#### B. æ ¡å‡†æ›²çº¿å›¾ (`calib_{protocol}.png`)

```python
# ç”Ÿæˆ: src/utils/visualizer.py :: save_calibration_curve()

å†…å®¹:
- Xè½´: Mean Predicted Probability
- Yè½´: Fraction of Positives
- æ›²çº¿: Calibration curve (bins)
- æ ‡æ³¨: ECE = 0.xxxx
- è­¦å‘Š: "âš ï¸ Small sample, bins reduced to N" (å¦‚æœ bins < 10)
- åŸºçº¿: å¯¹è§’çº¿ï¼ˆå®Œç¾æ ¡å‡†ï¼‰
```

#### C. æ•°æ®åˆ†å‰²ç»Ÿè®¡è¡¨ (`splits_{protocol}.csv`)

**å¿…éœ€13åˆ—**:

| åˆ—å | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|-----|------|------|------|
| split | str | åˆ†å‰²åç§° | train, val, test |
| count | int | æ ·æœ¬æ•° | 7000 |
| pos_count | int | æ­£æ ·æœ¬æ•°ï¼ˆé’“é±¼ï¼‰ | 3500 |
| neg_count | int | è´Ÿæ ·æœ¬æ•°ï¼ˆåˆæ³•ï¼‰ | 3500 |
| brand_unique | int | å”¯ä¸€å“ç‰Œæ•° | 25 |
| brand_set | str | å“ç‰Œåˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰ | ['google', 'paypal', ...] |
| timestamp_min | str | æœ€æ—©æ—¶é—´æˆ³ | 2023-01-01 00:00:00 |
| timestamp_max | str | æœ€æ™šæ—¶é—´æˆ³ | 2023-12-31 23:59:59 |
| source_counts | str | æ•°æ®æºç»Ÿè®¡ | {'source_a': 1000, ...} |
| brand_intersection_ok | bool | å“ç‰Œä¸é‡å ï¼ˆbrand_oodï¼‰ | true/false |
| tie_policy | str | æ—¶é—´æˆ³å¹¶åˆ—ç­–ç•¥ï¼ˆtemporalï¼‰ | left-closed |
| brand_normalization | str | å“ç‰Œå½’ä¸€åŒ–æ–¹æ³•ï¼ˆbrand_oodï¼‰ | strip+lower |
| downgraded_to | str | é™çº§åè®®ï¼ˆå¦‚æœ‰ï¼‰ | random / "" |

**ç”Ÿæˆ**: `src/utils/splits.py :: write_split_table()`

#### D. æŒ‡æ ‡JSON (`metrics_{protocol}.json`)

**å¿…éœ€å­—æ®µ**:

```json
{
  "accuracy": 0.9234,           // å‡†ç¡®ç‡
  "auroc": 0.9567,              // AUROC (pos_label=1)
  "f1_macro": 0.9201,           // å®å¹³å‡F1
  "nll": 0.1823,                // è´Ÿå¯¹æ•°ä¼¼ç„¶
  "ece": 0.0234,                // æœŸæœ›æ ¡å‡†è¯¯å·®
  "ece_bins_used": 10,          // ECEè®¡ç®—ä½¿ç”¨çš„binsæ•°
  "positive_class": "phishing", // æ­£ç±»åç§°

  "artifacts": {
    "roc_path": "results/roc_random.png",
    "calib_path": "results/calib_random.png",
    "splits_path": "results/splits_random.csv"
  },

  "warnings": {
    "downgraded_reason": null   // é™çº§åŸå› ï¼ˆå¦‚æœ‰ï¼‰
  }
}
```

**ç”Ÿæˆ**: `src/utils/protocol_artifacts.py :: ProtocolArtifactsCallback`

---

### 7.3 å®éªŒè·Ÿè¸ª

```python
# ä½ç½®: src/utils/experiment_tracker.py

class ExperimentTracker:
    """
    å®éªŒç®¡ç†å·¥å…·

    åŠŸèƒ½:
    1. åˆ›å»ºå”¯ä¸€å®éªŒç›®å½•: experiments/{name}_{timestamp}
    2. ä¿å­˜é…ç½®: config/config.yaml
    3. åˆ›å»ºå­ç›®å½•: checkpoints/, results/
    4. è®°å½•å®éªŒå…ƒæ•°æ®
    """

    def __init__(self, cfg, exp_name):
        self.exp_dir = f"experiments/{exp_name}_{timestamp}"
        self.config_dir = self.exp_dir / "config"
        self.results_dir = self.exp_dir / "results"
        self.checkpoints_dir = self.exp_dir / "checkpoints"

        # åˆ›å»ºç›®å½•
        self.exp_dir.mkdir(parents=True)
        self.config_dir.mkdir()
        self.results_dir.mkdir()

        # ä¿å­˜é…ç½®
        OmegaConf.save(cfg, self.config_dir / "config.yaml")
```

---

## 8. æ–‡æ¡£ç³»ç»Ÿ

### 8.1 URLæ¨¡å—æ–‡æ¡£

```
# å¿«é€Ÿå‚è€ƒ
URL_ONLY_QUICKREF.md         # å¿«é€Ÿå‘½ä»¤å‚è€ƒå¡
URL_ONLY_CLOSURE_GUIDE.md    # æ”¶å®˜æŒ‡å—

# è¯¦ç»†æŒ‡å—
docs/QUICKSTART_MLOPS_PROTOCOLS.md  # ä¸‰åè®®å¿«é€Ÿå¼€å§‹
docs/DATA_README.md                 # æ•°æ®è¯´æ˜
docs/WANDB_GUIDE.md                 # WandBé›†æˆæŒ‡å—
QUICK_START_DOCS.md                 # é¡¹ç›®å¿«é€Ÿå¼€å§‹

# å®ç°æŠ¥å‘Š
IMPLEMENTATION_REPORT.md     # MLOpså®ç°æŠ¥å‘Š
CHANGES_SUMMARY.md           # å˜æ›´æ€»ç»“
FINAL_SUMMARY_CN.md          # é¡¹ç›®æ€»ç»“ï¼ˆä¸­æ–‡ï¼‰
```

### 8.2 è‡ªåŠ¨æ–‡æ¡£è¿½åŠ 

```python
# ä½ç½®: src/utils/documentation.py, src/utils/doc_callback.py

# åŠŸèƒ½: è®­ç»ƒå®Œæˆåè‡ªåŠ¨è¿½åŠ å®éªŒè®°å½•åˆ°é¡¹ç›®æ–‡æ¡£

# å¯ç”¨æ–¹å¼
python scripts/train_hydra.py \
  protocol=random \
  use_build_splits=true \
  logging.auto_append_docs=true \
  logging.append_to_summary=true
```

---

## 9. å®Œæ•´æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        1. æ•°æ®å‡†å¤‡                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
        data/raw/{dataset, fish_dataset}/*.csv
                               â†“
         [scripts/create_master_csv.py]
                               â†“
              data/processed/master.csv
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        2. æ•°æ®åˆ†å‰²                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
              [UrlDataModule.setup() + build_splits()]
                   â†™         â†“         â†˜
        url_train.csv   url_val.csv   url_test.csv
                   â†˜         â†“         â†™
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        3. æ•°æ®åŠ è½½                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                    [UrlDataset: å­—ç¬¦çº§ç¼–ç ]
                               â†“
                  DataLoader (batch: tupleæ ¼å¼)
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        4. æ¨¡å‹è®­ç»ƒ                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
              [UrlOnlyModule: Encoder + Classifier]
                               â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â†“                 â†“                 â†“
   training_step()   validation_step()   test_step()
           â†“                 â†“                 â†“
      train_loss        val_loss/acc       test_metrics
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        5. äº§ç‰©ç”Ÿæˆ                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
         [ProtocolArtifactsCallback.on_test_end()]
                               â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â†“          â†“        â†“        â†“          â†“
    roc_{p}.png  calib_{p}.png  splits_{p}.csv  metrics_{p}.json
                               â†“
           [ResultVisualizer.create_all_plots()]
                               â†“
              experiments/{name}_{timestamp}/results/
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        6. éªŒè¯æ£€æŸ¥                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
              [tools/check_artifacts_url_only.py]
                               â†“
                    âœ… éªŒè¯é€šè¿‡ / âŒ å‘ç°é—®é¢˜
```

---

## 10. å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

### 10.1 æ•°æ®å‡†å¤‡

```bash
# ç”Ÿæˆä¸»æ•°æ®é›†
python scripts/create_master_csv.py

# æ£€æŸ¥æ•°æ®
ls -lh data/processed/*.csv
head -n 5 data/processed/master.csv
```

### 10.2 è®­ç»ƒè¿è¡Œ

```bash
# å•åè®®ï¼ˆå®Œæ•´è®­ç»ƒï¼‰
python scripts/train_hydra.py protocol=random use_build_splits=true

# å¿«é€Ÿæµ‹è¯•ï¼ˆ10%æ•°æ®ï¼Œ5 epochsï¼‰
python scripts/train_hydra.py protocol=random use_build_splits=true +profiles/local

# ä¸‰åè®®ä¸€é”®è¿è¡Œ
bash scripts/run_all_protocols.sh  # Linux/Mac
.\scripts\run_all_protocols.ps1    # Windows
```

### 10.3 éªŒè¯æ£€æŸ¥

```bash
# éªŒè¯æœ€æ–°å®éªŒ
python tools/check_artifacts_url_only.py

# éªŒè¯ç‰¹å®šå®éªŒ
python tools/check_artifacts_url_only.py experiments/url_random_20251022_120000

# æŸ¥çœ‹å®éªŒåˆ—è¡¨
ls -lt experiments/
```

### 10.4 æ¨ç†é¢„æµ‹

```bash
# å•URLé¢„æµ‹
python scripts/predict.py \
  --checkpoint experiments/url_only/checkpoints/url-only-best.ckpt \
  --url "https://suspicious-site.com/login"

# æ‰¹é‡é¢„æµ‹
python scripts/predict.py \
  --checkpoint experiments/url_only/checkpoints/url-only-best.ckpt \
  --test data/new_urls.csv \
  --out predictions.csv
```

---

## 11. æ•…éšœæ’é™¤

### é—®é¢˜1: ç¼ºå°‘ master.csv
```bash
# è§£å†³: è¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬
python scripts/create_master_csv.py
```

### é—®é¢˜2: ç¼ºå°‘ splits_*.csv
```bash
# è§£å†³: ç¡®ä¿å¯ç”¨ use_build_splits
python scripts/train_hydra.py protocol=random use_build_splits=true
```

### é—®é¢˜3: æ ¡å‡†å›¾æ²¡æœ‰ECEæ ‡æ³¨
```bash
# æ£€æŸ¥: src/utils/visualizer.py ç¬¬529-532è¡Œ
# åº”è¯¥æœ‰: ax.text(0.05, 0.95, f"ECE = {ece_value:.4f}", ...)
```

### é—®é¢˜4: brand_intersection_ok ä¸ºç©º
```bash
# åŸå› : master.csv ç¼ºå°‘ brand åˆ—
# è§£å†³: ç¡®ä¿åŸå§‹æ•°æ®åŒ…å«å“ç‰Œä¿¡æ¯
# å¯¹äº brand_oodï¼Œè‡³å°‘éœ€è¦3ä¸ªä¸åŒå“ç‰Œ
```

### é—®é¢˜5: è®­ç»ƒé€Ÿåº¦æ…¢
```bash
# å‡å°‘æ•°æ®é‡ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python scripts/train_hydra.py protocol=random use_build_splits=true +profiles/local

# å‡å°‘workers
python scripts/train_hydra.py protocol=random use_build_splits=true data.num_workers=0

# ä½¿ç”¨æ›´å°çš„batch size
python scripts/train_hydra.py protocol=random use_build_splits=true train.bs=16
```

---

## 12. æ€§èƒ½æŒ‡æ ‡å‚è€ƒ

### 12.1 æ¨¡å‹è§„æ¨¡

| ç»„ä»¶ | å‚æ•°é‡ | è¯´æ˜ |
|-----|--------|------|
| Embedding | 16K | 128Ã—128 |
| BiLSTM | ~200K | 2å±‚Ã—åŒå‘Ã—128 |
| Projection | 65K | 256Ã—256 |
| Classifier | 512 | 256Ã—2 |
| **æ€»è®¡** | **~282K** | è½»é‡çº§æ¨¡å‹ |

### 12.2 è®­ç»ƒæ—¶é—´å‚è€ƒ

| é…ç½® | æ•°æ®é‡ | Epochs | ç¡¬ä»¶ | æ—¶é—´ |
|-----|--------|--------|------|------|
| Local | 10% | 5 | CPU | ~2åˆ†é’Ÿ |
| Server | 100% | 50 | CPU | ~30åˆ†é’Ÿ |
| Server | 100% | 50 | GPU | ~10åˆ†é’Ÿ |

### 12.3 æ€§èƒ½åŸºçº¿

| åè®® | Accuracy | AUROC | F1-macro | ECE |
|-----|----------|-------|----------|-----|
| Random | ~0.92 | ~0.95 | ~0.91 | <0.05 |
| Temporal | ~0.89 | ~0.93 | ~0.88 | <0.06 |
| Brand-OOD | ~0.85 | ~0.90 | ~0.84 | <0.08 |

*æ³¨: å®é™…æ€§èƒ½å–å†³äºæ•°æ®è´¨é‡å’Œåˆ†å¸ƒ*

---

## 13. æ‰©å±•ä¸å®šåˆ¶

### 13.1 æ·»åŠ æ–°åè®®

```python
# 1. åœ¨ src/utils/splits.py æ·»åŠ æ–°åˆ†å‰²å‡½æ•°
def _custom_split(df, train_ratio, val_ratio, test_ratio):
    # å®ç°è‡ªå®šä¹‰åˆ†å‰²é€»è¾‘
    ...
    return train_df, val_df, test_df

# 2. åœ¨ build_splits() æ·»åŠ åè®®åˆ†æ”¯
if protocol == "custom":
    train_df, val_df, test_df = _custom_split(...)
    metadata["custom_field"] = "..."
```

### 13.2 ä¿®æ”¹æ¨¡å‹æ¶æ„

**âš ï¸ è­¦å‘Š**: URLç¼–ç å™¨æ¶æ„å·²é”å®šï¼Œä¿®æ”¹éœ€è¦:

1. ç§»é™¤æ–­è¨€ä¿æŠ¤: `src/systems/url_only_module.py` ç¬¬38-43è¡Œ
2. ä¿®æ”¹é…ç½®: `configs/model/url_encoder.yaml`
3. é‡æ–°è®­ç»ƒæ‰€æœ‰åè®®
4. æ›´æ–°æ–‡æ¡£è¯´æ˜ä¿®æ”¹åŸå› 

### 13.3 æ·»åŠ æ–°æŒ‡æ ‡

```python
# 1. åœ¨ src/utils/metrics.py å®ç°æ–°æŒ‡æ ‡
def compute_custom_metric(y_true, y_pred):
    ...
    return metric_value

# 2. åœ¨ UrlOnlyModule æ·»åŠ æŒ‡æ ‡è®¡ç®—
def on_test_epoch_end(self):
    custom_metric = compute_custom_metric(...)
    self.log("test_custom", custom_metric)

# 3. åœ¨ ProtocolArtifactsCallback æ·»åŠ åˆ°metrics.json
metrics_dict["custom_metric"] = float(logged_metrics.get("test_custom", 0.0))
```

---

## 14. ä¾èµ–ç¯å¢ƒ

### 14.1 æ ¸å¿ƒä¾èµ–

```txt
# requirements.txt (æ ¸å¿ƒ)
torch>=1.13.0
pytorch-lightning>=2.0.0
pandas>=1.5.0
numpy>=1.23.0
omegaconf>=2.3.0
hydra-core>=1.3.0

# å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
matplotlib>=3.6.0
seaborn>=0.12.0

# æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
wandb>=0.13.0
tensorboard>=2.11.0
```

### 14.2 ç¯å¢ƒé…ç½®

```bash
# ä½¿ç”¨ condaï¼ˆæ¨èï¼‰
conda env create -f environment.yml
conda activate uaam-phish

# æˆ–ä½¿ç”¨ pip
pip install -r requirements.txt

# æˆ–å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .
```

---

## 15. é¡¹ç›®æ–‡ä»¶ç´¢å¼•

### æ ¸å¿ƒä»£ç  (src/)
- `src/data/url_dataset.py` - URLæ•°æ®é›†ç±»
- `src/datamodules/url_datamodule.py` - Lightningæ•°æ®æ¨¡å—
- `src/models/url_encoder.py` - BiLSTMç¼–ç å™¨
- `src/systems/url_only_module.py` - è®­ç»ƒç³»ç»Ÿæ¨¡å—
- `src/utils/splits.py` - æ•°æ®åˆ†å‰²å·¥å…·
- `src/utils/metrics.py` - æŒ‡æ ‡è®¡ç®—ï¼ˆECE, NLLï¼‰
- `src/utils/visualizer.py` - å¯è§†åŒ–å·¥å…·
- `src/utils/protocol_artifacts.py` - äº§ç‰©ç”Ÿæˆå›è°ƒ
- `src/utils/callbacks.py` - å…¶ä»–å›è°ƒ
- `src/utils/experiment_tracker.py` - å®éªŒè·Ÿè¸ª

### è„šæœ¬ (scripts/)
- `scripts/train_hydra.py` - Hydraè®­ç»ƒè„šæœ¬ï¼ˆä¸»å…¥å£ï¼‰
- `scripts/train.py` - ç®€å•è®­ç»ƒè„šæœ¬ï¼ˆæ—§ç‰ˆï¼‰
- `scripts/predict.py` - é¢„æµ‹è„šæœ¬
- `scripts/create_master_csv.py` - ç”Ÿæˆä¸»æ•°æ®é›†
- `scripts/build_master_and_splits.py` - æ•°æ®æ„å»ºï¼ˆDVCç‰ˆï¼‰
- `scripts/run_all_protocols.sh` - ä¸€é”®è¿è¡Œè„šæœ¬ï¼ˆLinux/Macï¼‰
- `scripts/run_all_protocols.ps1` - ä¸€é”®è¿è¡Œè„šæœ¬ï¼ˆWindowsï¼‰

### é…ç½® (configs/)
- `configs/config.yaml` - ä¸»é…ç½®
- `configs/data/url_only.yaml` - URLæ•°æ®é…ç½®
- `configs/model/url_encoder.yaml` - ç¼–ç å™¨é…ç½®
- `configs/experiment/url_baseline.yaml` - åŸºçº¿å®éªŒé…ç½®
- `configs/trainer/*.yaml` - è®­ç»ƒå™¨é…ç½®
- `configs/logger/*.yaml` - æ—¥å¿—é…ç½®

### å·¥å…· (tools/)
- `tools/check_artifacts_url_only.py` - äº§ç‰©éªŒè¯å·¥å…·

### æ–‡æ¡£ (docs/ & root)
- `URL_ONLY_QUICKREF.md` - å¿«é€Ÿå‚è€ƒ
- `URL_ONLY_CLOSURE_GUIDE.md` - æ”¶å®˜æŒ‡å—
- `docs/QUICKSTART_MLOPS_PROTOCOLS.md` - åè®®å¿«é€Ÿå¼€å§‹
- `IMPLEMENTATION_REPORT.md` - å®ç°æŠ¥å‘Š
- `CHANGES_SUMMARY.md` - å˜æ›´æ€»ç»“
- `FINAL_SUMMARY_CN.md` - é¡¹ç›®æ€»ç»“

---

## 16. è®¸å¯è¯ä¸å¼•ç”¨

### é¡¹ç›®ä¿¡æ¯
- **é¡¹ç›®åç§°**: UAAM-Phish (URL-Aware Anti-phishing Model)
- **æ¨¡å—**: URL-Only Baseline
- **æ¶æ„**: å­—ç¬¦çº§ 2å±‚BiLSTM (256ç»´è¾“å‡º)

### å¼•ç”¨
å¦‚æœä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ç›¸å…³è®ºæ–‡ï¼ˆå¾…è¡¥å……ï¼‰

---

---

## ğŸš€ å¿«é€Ÿè¿è¡Œå‘½ä»¤

### ä¸€é”®è¿è¡Œï¼ˆæ¨èï¼‰
```bash
# Linux/Mac
bash scripts/run_all_protocols.sh

# Windows PowerShell
.\scripts\run_all_protocols.ps1
```

### å•åè®®è¿è¡Œ
```bash
# Random
python scripts/train_hydra.py protocol=random use_build_splits=true

# Temporal
python scripts/train_hydra.py protocol=temporal use_build_splits=true

# Brand-OOD
python scripts/train_hydra.py protocol=brand_ood use_build_splits=true
```

### éªŒè¯äº§ç‰©
```bash
# è‡ªåŠ¨éªŒè¯æœ€æ–°å®éªŒ
python tools/check_artifacts_url_only.py

# éªŒè¯ç‰¹å®šå®éªŒ
python tools/check_artifacts_url_only.py experiments/url_random_20251022_120000
```

---

## ğŸ› ï¸ å‡†å¤‡å·¥ä½œ

```bash
# å¦‚æœæ²¡æœ‰ master.csvï¼Œå…ˆåˆ›å»º
python scripts/create_master_csv.py

# æ£€æŸ¥æ•°æ®
ls -lh data/processed/*.csv
```

---

## âœ… éªŒè¯æ¸…å•

### å››ä»¶å¥—æ–‡ä»¶å­˜åœ¨æ€§
- âœ… `roc_{protocol}.png` - ROCæ›²çº¿
- âœ… `calib_{protocol}.png` - æ ¡å‡†æ›²çº¿ï¼ˆå«ECEï¼‰
- âœ… `splits_{protocol}.csv` - åˆ†å‰²ç»Ÿè®¡
- âœ… `metrics_{protocol}.json` - å®Œæ•´æŒ‡æ ‡

### splits_{protocol}.csv åˆ—å®Œæ•´æ€§ï¼ˆ13åˆ—ï¼‰
- split, count, pos_count, neg_count, brand_unique, brand_set, timestamp_min, timestamp_max, source_counts, brand_intersection_ok, tie_policy, brand_normalization, downgraded_to

### metrics_{protocol}.json schema å®Œæ•´æ€§
- accuracy, auroc, f1_macro, nll, ece, ece_bins_used, positive_class, artifacts, warnings

### ECE bins èŒƒå›´åˆç†æ€§ [3, 15]
- è‡ªé€‚åº”è®¡ç®—ï¼š`max(3, min(15, floor(sqrt(N)), 10))`

### åè®®ç‰¹å®šéªŒè¯
- brand_ood çš„ brand_intersection_ok
- temporal çš„ tie_policy

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-10-22
**ç»´æŠ¤è€…**: AI Assistant

---
