# ä¸‹ä¸€æ­¥è¡ŒåŠ¨æŒ‡å—

> **æ›´æ–°æ—¶é—´**: 2025-10-23
> **å½“å‰çŠ¶æ€**: âœ… é…ç½®æ£€æŸ¥å®Œæˆï¼Œç³»ç»Ÿå°±ç»ª

---

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. é…ç½®æ£€æŸ¥
- âœ… Hydraé…ç½®æ­£å¸¸åŠ è½½
- âœ… æ‰€æœ‰æ¨¡å‹ã€æ•°æ®ã€è®­ç»ƒå™¨é…ç½®æ­£ç¡®
- âœ… æ”¯æŒç¯å¢ƒå˜é‡åŠ¨æ€åˆ‡æ¢æ•°æ®é›†
- âœ… WandBé›†æˆå°±ç»ª

### 2. åˆ›å»ºçš„æ–‡æ¡£å’Œé…ç½®
- âœ… `CONFIG_HEALTH_CHECK.md` - è¯¦ç»†é…ç½®æ£€æŸ¥æŠ¥å‘Š
- âœ… `CONFIG_CHECK_SUMMARY.md` - é…ç½®æ£€æŸ¥æ€»ç»“
- âœ… `TRAINING_PLAYBOOK.md` - å®Œæ•´è®­ç»ƒæ“ä½œæ‰‹å†Œ
- âœ… `FINAL_SUMMARY_CN.md` - å®Œæ•´é¡¹ç›®æŒ‡å—ï¼ˆå·²æ›´æ–°ï¼‰
- âœ… `configs/data/url_large.yaml` - å¤§æ•°æ®é›†é…ç½®
- âœ… `configs/trainer/multi_gpu.yaml` - å¤šGPUé…ç½®
- âœ… `configs/experiment/url_large_baseline.yaml` - å¤§æ•°æ®é›†å®éªŒé…ç½®

---

## ğŸ¯ æ‚¨ç°åœ¨å¯ä»¥åšçš„äº‹æƒ…

### é€‰é¡¹ 1: åœ¨å½“å‰å°æ•°æ®é›†ä¸Šå¿«é€ŸéªŒè¯ âœ… æ¨èå…ˆåšè¿™ä¸ª

```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆ2-3åˆ†é’Ÿï¼‰
python scripts/train_hydra.py trainer=local data.sample_fraction=0.1 train.epochs=2

# å®Œæ•´è®­ç»ƒï¼ˆ10-15åˆ†é’Ÿï¼‰
python scripts/train_hydra.py trainer=server logger=wandb run.name=small_dataset_baseline
```

**ç›®çš„**: ç¡®ä¿æµç¨‹å®Œå…¨æ­£å¸¸å†åˆ‡æ¢å¤§æ•°æ®é›†

### é€‰é¡¹ 2: åˆ‡æ¢åˆ°å¤§æ•°æ®é›†è®­ç»ƒ

#### Step 1: å‡†å¤‡å¤§æ•°æ®é›†

```bash
# é¢„å¤„ç†å¤§æ•°æ®é›†
python scripts/build_master_and_splits.py \
  --benign D:\large_dataset\benign \
  --phish D:\large_dataset\phish \
  --outdir D:\large_dataset\processed

# éªŒè¯æ•°æ®
python scripts/validate_data_schema.py --data_root D:\large_dataset\processed
```

#### Step 2: è®¾ç½®ç¯å¢ƒå˜é‡

```powershell
# Windows PowerShell
$env:DATA_ROOT = "D:\large_dataset\processed"
$env:WANDB_PROJECT = "uaam-phish-large"

# éªŒè¯
echo $env:DATA_ROOT
```

#### Step 3: å¿«é€Ÿæµ‹è¯•ï¼ˆ10%æ•°æ®ï¼‰

```bash
python scripts/train_hydra.py `
  data=url_large `
  trainer=server `
  data.sample_fraction=0.1 `
  train.epochs=5 `
  logger=wandb `
  run.name=large_quick_test
```

#### Step 4: å®Œæ•´è®­ç»ƒ

```bash
# ä½¿ç”¨å®éªŒé…ç½®ï¼ˆæ¨èï¼‰
python scripts/train_hydra.py experiment=url_large_baseline

# æˆ–æ‰‹åŠ¨æŒ‡å®š
python scripts/train_hydra.py `
  data=url_large `
  trainer=server `
  logger=wandb `
  run.name=large_url_baseline_v1
```

### é€‰é¡¹ 3: è¿è¡Œæ‰€æœ‰æ•°æ®åˆ†å‰²åè®®

```bash
# æ‰¹é‡è¿è¡Œ
.\scripts\run_all_protocols.ps1

# æˆ–æ‰‹åŠ¨è¿è¡Œ
python scripts/train_hydra.py protocol=random logger=wandb run.name=large_random
python scripts/train_hydra.py protocol=temporal logger=wandb run.name=large_temporal
python scripts/train_hydra.py protocol=brand_ood logger=wandb run.name=large_brand_ood
```

### é€‰é¡¹ 4: è¶…å‚æ•°æœç´¢

```bash
# æœç´¢æœ€ä½³å­¦ä¹ ç‡
python scripts/train_hydra.py -m `
  experiment=url_large_baseline `
  train.lr=1e-3,5e-4,1e-4,5e-5 `
  run.name=lr_search

# æœç´¢dropoutå’Œbatch size
python scripts/train_hydra.py -m `
  model.dropout=0.1,0.2,0.3 `
  train.batch_size=64,128,256 `
  trainer=server `
  logger=wandb
```

---

## ğŸ“‹ æ¨èçš„è®­ç»ƒé¡ºåº

### ğŸš€ å¿«é€Ÿå…¥é—¨è·¯å¾„ï¼ˆæ¨èï¼‰

```
1ï¸âƒ£ å°æ•°æ®é›†å¿«é€ŸéªŒè¯ï¼ˆ5åˆ†é’Ÿï¼‰
   â†“
2ï¸âƒ£ æŸ¥çœ‹ç»“æœï¼Œç¡®è®¤æµç¨‹
   â†“
3ï¸âƒ£ å‡†å¤‡å¤§æ•°æ®é›†
   â†“
4ï¸âƒ£ å¤§æ•°æ®é›†10%æµ‹è¯•
   â†“
5ï¸âƒ£ å¤§æ•°æ®é›†å®Œæ•´è®­ç»ƒ
   â†“
6ï¸âƒ£ è¶…å‚æ•°è°ƒä¼˜
   â†“
7ï¸âƒ£ æœ€ç»ˆæ¨¡å‹
```

### ğŸ“ å…·ä½“å‘½ä»¤

```bash
# 1ï¸âƒ£ å¿«é€ŸéªŒè¯
python scripts/train_hydra.py trainer=local data.sample_fraction=0.1 train.epochs=2

# 2ï¸âƒ£ æŸ¥çœ‹ç»“æœ
python scripts/compare_experiments.py --latest 1

# 3ï¸âƒ£ å‡†å¤‡å¤§æ•°æ®é›†ï¼ˆæ ¹æ®å®é™…æƒ…å†µï¼‰
# è·³è¿‡æ­¤æ­¥éª¤å¦‚æœæ•°æ®å·²å‡†å¤‡å¥½

# 4ï¸âƒ£ è®¾ç½®ç¯å¢ƒå˜é‡å¹¶æµ‹è¯•
$env:DATA_ROOT = "D:\large_dataset\processed"
python scripts/train_hydra.py data=url_large data.sample_fraction=0.1 train.epochs=5

# 5ï¸âƒ£ å®Œæ•´è®­ç»ƒ
python scripts/train_hydra.py experiment=url_large_baseline

# 6ï¸âƒ£ è¶…å‚æ•°è°ƒä¼˜
python scripts/train_hydra.py -m experiment=url_large_baseline train.lr=1e-3,5e-4,1e-4

# 7ï¸âƒ£ æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
python scripts/compare_experiments.py --find_best --metric auroc
```

---

## ğŸ“ å›å¤´è®­ç»ƒæŒ‡å—

### Hydraè®©å›å¤´è®­ç»ƒå˜å¾—è¶…çº§ç®€å•ï¼

#### æ–¹å¼ 1: ä½¿ç”¨ä¿å­˜çš„é…ç½®

```bash
# æ¯æ¬¡è®­ç»ƒéƒ½ä¼šä¿å­˜å®Œæ•´é…ç½®åˆ°
# experiments/<run_name>/config.yaml

# å›å¤´ä½¿ç”¨ç›¸åŒé…ç½®
python scripts/train_hydra.py \
  --config-path ../experiments/<run_name> \
  --config-name config
```

#### æ–¹å¼ 2: ä½¿ç”¨å®éªŒé…ç½®åç§°

```bash
# ä¿å­˜æœ€ä½³é…ç½®ä¸ºå®éªŒé…ç½®
# configs/experiment/my_best.yaml

# éšæ—¶å›å¤´è®­ç»ƒ
python scripts/train_hydra.py experiment=my_best
```

#### æ–¹å¼ 3: è®°å½•å‘½ä»¤è¡Œå‚æ•°

```bash
# åœ¨WandBä¸­è‡ªåŠ¨è®°å½•æ‰€æœ‰å‚æ•°
# ç›´æ¥å¤åˆ¶å‘½ä»¤å³å¯é‡ç°

# ä¾‹å¦‚ï¼š
python scripts/train_hydra.py \
  model=url_encoder \
  data=url_large \
  train.lr=5e-4 \
  train.batch_size=128 \
  trainer=server \
  logger=wandb
```

#### æ–¹å¼ 4: å¯¹æ¯”å†å²å®éªŒ

```bash
# æŸ¥çœ‹å†å²å®éªŒ
python scripts/compare_experiments.py --latest 20

# æ‰¾åˆ°æœ€ä½³å®éªŒ
python scripts/compare_experiments.py --find_best --metric auroc

# æŸ¥çœ‹è¯¥å®éªŒçš„é…ç½®
cat experiments/<best_run_name>/config.yaml

# å¤ç°
python scripts/train_hydra.py \
  --config-path ../experiments/<best_run_name> \
  --config-name config
```

---

## ğŸ”® æœªæ¥è®­ç»ƒè·¯çº¿å›¾

### é˜¶æ®µ 1: URLå•æ¨¡å‹ï¼ˆç°åœ¨ï¼‰

```bash
# å½“å‰çŠ¶æ€ï¼šâœ… å®Œå…¨å°±ç»ª
python scripts/train_hydra.py experiment=url_large_baseline
```

### é˜¶æ®µ 2: å¤šæ¨¡å‹ç‹¬ç«‹è®­ç»ƒï¼ˆéœ€è¦å®ç°æ¨¡å‹ä»£ç ï¼‰

```bash
# HTMLæ¨¡å‹
python scripts/train_hydra.py model=html_encoder data=html_only

# å›¾åƒæ¨¡å‹
python scripts/train_hydra.py model=image_encoder data=image_only
```

**éœ€è¦åšçš„**:
1. å®ç° `src/models/html_encoder.py`
2. å®ç° `src/models/image_encoder.py`
3. æ·»åŠ é…ç½®æ–‡ä»¶ï¼ˆå¯å‚è€ƒ `CONFIG_HEALTH_CHECK.md` ä¸­çš„ç¤ºä¾‹ï¼‰

### é˜¶æ®µ 3: å¤šæ¨¡æ€èåˆï¼ˆéœ€è¦å®ç°èåˆæ¨¡å—ï¼‰

```bash
# RCAFèåˆ
python scripts/train_hydra.py model=multimodal_rcaf data=multimodal
```

**éœ€è¦åšçš„**:
1. å®ç° `src/modules/fusion/rcaf.py`
2. å®ç° `src/systems/multimodal_rcaf_module.py`
3. æ·»åŠ é…ç½®æ–‡ä»¶

**Hydraçš„ä¼˜åŠ¿**: åªéœ€æ·»åŠ é…ç½®æ–‡ä»¶ï¼Œæ— éœ€ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼

---

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

### è®­ç»ƒ

```bash
# æœ¬åœ°å¿«é€Ÿæµ‹è¯•
python scripts/train_hydra.py trainer=local

# GPUè®­ç»ƒ
python scripts/train_hydra.py trainer=server logger=wandb

# å¤§æ•°æ®é›†
python scripts/train_hydra.py experiment=url_large_baseline

# å¤šGPU
python scripts/train_hydra.py trainer=multi_gpu data=url_large
```

### æ•°æ®

```bash
# éªŒè¯æ•°æ®
python scripts/validate_data_schema.py

# é¢„å¤„ç†
python scripts/build_master_and_splits.py --benign <path> --phish <path>

# æ£€æŸ¥é‡å 
python check_overlap.py
```

### ç»“æœ

```bash
# å¯¹æ¯”å®éªŒ
python scripts/compare_experiments.py --latest 5

# æŸ¥æ‰¾æœ€ä½³
python scripts/compare_experiments.py --find_best --metric auroc

# å¯¼å‡ºç»“æœ
python scripts/compare_experiments.py --latest 10 --output results.csv
```

---

## ğŸ“š æ–‡æ¡£ç´¢å¼•

| æ–‡æ¡£ | ç”¨é€” | ä½•æ—¶æŸ¥çœ‹ |
|------|------|----------|
| `CONFIG_CHECK_SUMMARY.md` | é…ç½®æ£€æŸ¥æ€»ç»“ | ç°åœ¨ - å¿«é€Ÿäº†è§£é…ç½®çŠ¶æ€ |
| `TRAINING_PLAYBOOK.md` | è®­ç»ƒæ“ä½œæ‰‹å†Œ | è®­ç»ƒæ—¶ - æŸ¥çœ‹è¯¦ç»†æ­¥éª¤ |
| `CONFIG_HEALTH_CHECK.md` | è¯¦ç»†é…ç½®æŠ¥å‘Š | æ·»åŠ æ–°æ¨¡å‹æ—¶ - å‚è€ƒé…ç½®ç¤ºä¾‹ |
| `FINAL_SUMMARY_CN.md` | å®Œæ•´é¡¹ç›®æŒ‡å— | ä»»ä½•æ—¶å€™ - å®Œæ•´å‚è€ƒ |
| `QUICKSTART_MLOPS.md` | MLOpså¿«é€Ÿå¼€å§‹ | å¼€å§‹å‰ - äº†è§£MLOpsåŠŸèƒ½ |

---

## âœ… å»ºè®®çš„ä¸‹ä¸€æ­¥

### ğŸ¯ ç«‹å³è¡ŒåŠ¨ï¼ˆ5åˆ†é’Ÿå†…ï¼‰

```bash
# 1. å¿«é€ŸéªŒè¯ç³»ç»Ÿ
python scripts/train_hydra.py `
  trainer=local `
  data.sample_fraction=0.1 `
  train.epochs=2

# 2. æŸ¥çœ‹ç»“æœ
python scripts/compare_experiments.py --latest 1
```

### ğŸ“… ä»Šå¤©å®Œæˆ

1. âœ… åœ¨å°æ•°æ®é›†ä¸Šå®Œæ•´è®­ç»ƒä¸€æ¬¡
2. âœ… ç†Ÿæ‚‰WandBç•Œé¢
3. âœ… å‡†å¤‡å¤§æ•°æ®é›†ï¼ˆå¦‚æœæœ‰ï¼‰

### ğŸ“… æœ¬å‘¨å®Œæˆ

1. å¤§æ•°æ®é›†è®­ç»ƒ
2. è¶…å‚æ•°è°ƒä¼˜
3. å¯¹æ¯”ä¸åŒåè®®ï¼ˆrandom/temporal/brand_oodï¼‰

### ğŸ“… æœªæ¥è®¡åˆ’

1. å®ç°HTMLç¼–ç å™¨
2. å®ç°å›¾åƒç¼–ç å™¨
3. å®ç°å¤šæ¨¡æ€èåˆ

---

## ğŸ’¡ é‡è¦æé†’

### âœ… Hydraå®Œç¾æ”¯æŒæ‚¨çš„éœ€æ±‚

- âœ… **å•æ¨¡å‹**: ç›´æ¥ç”¨ç°æœ‰é…ç½®
- âœ… **å¤šæ¨¡å‹**: æ·»åŠ é…ç½®æ–‡ä»¶å³å¯
- âœ… **å¤šæ¨¡æ€èåˆ**: Hydraæ”¯æŒåµŒå¥—é…ç½®
- âœ… **å›å¤´è®­ç»ƒ**: é…ç½®æ°¸ä¹…ä¿å­˜ï¼Œä¸€æ¡å‘½ä»¤å¤ç°

### âœ… é…ç½®å¥åº·çŠ¶æ€

- âœ… å½“å‰é…ç½®å®Œå…¨æ­£å¸¸
- âœ… æ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç 
- âœ… å¤§æ•°æ®é›†åˆ‡æ¢åªéœ€ç¯å¢ƒå˜é‡
- âœ… æ‰€æœ‰åŠŸèƒ½å·²æµ‹è¯•éªŒè¯

---

## ğŸš€ å¼€å§‹å§ï¼

### æœ€ç®€å•çš„å¼€å§‹æ–¹å¼

```bash
# ä¸€æ¡å‘½ä»¤ï¼Œç«‹å³å¼€å§‹
python scripts/train_hydra.py trainer=local data.sample_fraction=0.1 train.epochs=2
```

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ‰

---

**æœ‰ä»»ä½•é—®é¢˜ï¼Œéšæ—¶æŸ¥é˜…æ–‡æ¡£æˆ–è¯¢é—®ï¼**
