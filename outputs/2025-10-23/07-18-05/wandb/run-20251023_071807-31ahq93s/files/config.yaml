_wandb:
    value:
        cli_version: 0.19.1
        m:
            - "1": train_acc
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
            - "1": val_accuracy
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": val_auroc
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": val_loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": val_ece
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": train_loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": val_acc
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": val_f1
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": val_nll
              "5": 2
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.12.2
        t:
            "1":
                - 1
                - 5
                - 9
                - 11
                - 41
                - 49
                - 50
                - 53
                - 55
                - 103
                - 105
            "2":
                - 1
                - 5
                - 9
                - 11
                - 41
                - 49
                - 50
                - 53
                - 55
                - 103
                - 105
            "3":
                - 7
                - 13
                - 23
                - 55
                - 66
            "4": 3.12.2
            "5": 0.19.1
            "6": 4.47.1
            "8":
                - 3
                - 5
            "12": 0.19.1
            "13": windows-amd64
cfg:
    value:
        data:
            batch_format: tuple
            brand_col: brand
            csv_path: data/processed/master.csv
            label_col: label
            min_len: 1
            num_workers: 4
            source_col: source
            split_ratios:
                test: 0.15
                train: 0.7
                val: 0.15
            test_csv: data/processed/url_test.csv
            text_col: url_text
            timestamp_col: timestamp
            train_csv: data/processed/url_train.csv
            val_csv: data/processed/url_val.csv
        eval:
            bs: 64
            monitor: val_loss
            patience: 5
        hardware:
            accelerator: cpu
            devices: 1
            num_workers: 8
            precision: 32
            strategy: auto
        logger:
            _target_: pytorch_lightning.loggers.WandbLogger
            entity: null
            log_model: false
            name: url_baseline
            notes: null
            offline: false
            project: uaam-phish
            save_dir: D:\uaam-phish\outputs\2025-10-23\07-18-05
            tags: null
        model:
            _target_: src.models.url_encoder.URLEncoder
            bidirectional: true
            dropout: 0.2
            embedding_dim: 128
            hidden_dim: 128
            max_len: 256
            num_classes: 2
            num_layers: 2
            pad_id: 0
            pretrained_name: roberta-base
            proj_dim: 256
            vocab_size: 128
        paths:
            data_root: data/processed
            test_index: data/processed/test.csv
            train_index: data/processed/train.csv
            val_index: data/processed/val.csv
        run:
            name: url_baseline
            seed: 42
            tags:
                - url-only
                - baseline
                - roberta
        train:
            bs: 32
            epochs: 10
            log_every: 50
            lr: 2e-05
            weight_decay: 1e-05
